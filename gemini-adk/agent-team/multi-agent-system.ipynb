{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f64d0752",
   "metadata": {},
   "source": [
    "# 1. ADK Primitives for Agent Composition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c2aa8e",
   "metadata": {},
   "source": [
    "## 1.1. Agent Hierarchy (Parent agent, Sub Agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a71dba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conceptual Example: Defining Hierarchy\n",
    "from google.adk.agents import LlmAgent, BaseAgent\n",
    "\n",
    "# Define individual agents\n",
    "greeter = LlmAgent(name=\"Greeter\", model=\"gemini-2.0-flash\")\n",
    "task_doer = BaseAgent(name=\"TaskExecutor\") # Custom non-LLM agent\n",
    "\n",
    "# Create parent agent and assign children via sub_agents\n",
    "coordinator = LlmAgent(\n",
    "    name=\"Coordinator\",\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    description=\"I coordinate greetings and tasks.\",\n",
    "    sub_agents=[ # Assign sub_agents here\n",
    "        greeter,\n",
    "        task_doer\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Framework automatically sets:\n",
    "# assert greeter.parent_agent == coordinator\n",
    "# assert task_doer.parent_agent == coordinator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3922efa",
   "metadata": {},
   "source": [
    "## 1.2. Workflow Agents as Orchestrators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ff0a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conceptual Example: Sequential Pipeline\n",
    "from google.adk.agents import SequentialAgent, LlmAgent\n",
    "\n",
    "step1 = LlmAgent(name=\"Step1_Fetch\", output_key=\"data\") # Saves output to state['data']\n",
    "step2 = LlmAgent(name=\"Step2_Process\", instruction=\"Process data from {data}.\")\n",
    "\n",
    "pipeline = SequentialAgent(name=\"MyPipeline\", sub_agents=[step1, step2])\n",
    "# When pipeline runs, Step2 can access the state['data'] set by Step1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "804f480f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conceptual Example: Parallel Execution\n",
    "from google.adk.agents import ParallelAgent, LlmAgent\n",
    "\n",
    "fetch_weather = LlmAgent(name=\"WeatherFetcher\", output_key=\"weather\")\n",
    "fetch_news = LlmAgent(name=\"NewsFetcher\", output_key=\"news\")\n",
    "\n",
    "gatherer = ParallelAgent(name=\"InfoGatherer\", sub_agents=[fetch_weather, fetch_news])\n",
    "# When gatherer runs, WeatherFetcher and NewsFetcher run concurrently.\n",
    "# A subsequent agent could read state['weather'] and state['news']."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8ff2cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conceptual Example: Loop with Condition\n",
    "from google.adk.agents import LoopAgent, LlmAgent, BaseAgent\n",
    "from google.adk.events import Event, EventActions\n",
    "from google.adk.agents.invocation_context import InvocationContext\n",
    "from typing import AsyncGenerator\n",
    "\n",
    "class CheckCondition(BaseAgent): # Custom agent to check state\n",
    "    async def _run_async_impl(self, ctx: InvocationContext) -> AsyncGenerator[Event, None]:\n",
    "        status = ctx.session.state.get(\"status\", \"pending\")\n",
    "        is_done = (status == \"completed\")\n",
    "        yield Event(author=self.name, actions=EventActions(escalate=is_done)) # Escalate if done\n",
    "\n",
    "process_step = LlmAgent(name=\"ProcessingStep\") # Agent that might update state['status']\n",
    "\n",
    "poller = LoopAgent(\n",
    "    name=\"StatusPoller\",\n",
    "    max_iterations=10,\n",
    "    sub_agents=[process_step, CheckCondition(name=\"Checker\")]\n",
    ")\n",
    "# When poller runs, it executes process_step then Checker repeatedly\n",
    "# until Checker escalates (state['status'] == 'completed') or 10 iterations pass."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c069ff6b",
   "metadata": {},
   "source": [
    "## 1.3. Interaction & Communication Mechanisms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0bfa4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conceptual Example: Using output_key and reading state\n",
    "from google.adk.agents import LlmAgent, SequentialAgent\n",
    "\n",
    "agent_A = LlmAgent(name=\"AgentA\", instruction=\"Find the capital of France.\", output_key=\"capital_city\")\n",
    "agent_B = LlmAgent(name=\"AgentB\", instruction=\"Tell me about the city stored in {capital_city}.\")\n",
    "\n",
    "pipeline = SequentialAgent(name=\"CityInfo\", sub_agents=[agent_A, agent_B])\n",
    "# AgentA runs, saves \"Paris\" to state['capital_city'].\n",
    "# AgentB runs, its instruction processor reads state['capital_city'] to get \"Paris\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56204842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conceptual Setup: LLM Transfer\n",
    "from google.adk.agents import LlmAgent\n",
    "\n",
    "booking_agent = LlmAgent(name=\"Booker\", description=\"Handles flight and hotel bookings.\")\n",
    "info_agent = LlmAgent(name=\"Info\", description=\"Provides general information and answers questions.\")\n",
    "\n",
    "coordinator = LlmAgent(\n",
    "    name=\"Coordinator\",\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    instruction=\"You are an assistant. Delegate booking tasks to Booker and info requests to Info.\",\n",
    "    description=\"Main coordinator.\",\n",
    "    # AutoFlow is typically used implicitly here\n",
    "    sub_agents=[booking_agent, info_agent]\n",
    ")\n",
    "# If coordinator receives \"Book a flight\", its LLM should generate:\n",
    "# FunctionCall(name='transfer_to_agent', args={'agent_name': 'Booker'})\n",
    "# ADK framework then routes execution to booking_agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3709c9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conceptual Setup: Agent as a Tool\n",
    "from google.adk.agents import LlmAgent, BaseAgent\n",
    "from google.adk.tools import agent_tool\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# Define a target agent (could be LlmAgent or custom BaseAgent)\n",
    "class ImageGeneratorAgent(BaseAgent): # Example custom agent\n",
    "    name: str = \"ImageGen\"\n",
    "    description: str = \"Generates an image based on a prompt.\"\n",
    "    # ... internal logic ...\n",
    "    async def _run_async_impl(self, ctx): # Simplified run logic\n",
    "        prompt = ctx.session.state.get(\"image_prompt\", \"default prompt\")\n",
    "        # ... generate image bytes ...\n",
    "        image_bytes = b\"...\"\n",
    "        yield Event(author=self.name, content=types.Content(parts=[types.Part.from_bytes(image_bytes, \"image/png\")]))\n",
    "\n",
    "image_agent = ImageGeneratorAgent()\n",
    "image_tool = agent_tool.AgentTool(agent=image_agent) # Wrap the agent\n",
    "\n",
    "# Parent agent uses the AgentTool\n",
    "artist_agent = LlmAgent(\n",
    "    name=\"Artist\",\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    instruction=\"Create a prompt and use the ImageGen tool to generate the image.\",\n",
    "    tools=[image_tool] # Include the AgentTool\n",
    ")\n",
    "# Artist LLM generates a prompt, then calls:\n",
    "# FunctionCall(name='ImageGen', args={'image_prompt': 'a cat wearing a hat'})\n",
    "# Framework calls image_tool.run_async(...), which runs ImageGeneratorAgent.\n",
    "# The resulting image Part is returned to the Artist agent as the tool result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7aa33cc",
   "metadata": {},
   "source": [
    "# 2. Common Multi-Agent Patterns using ADK Primitives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10c8a339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conceptual Code: Coordinator using LLM Transfer\n",
    "from google.adk.agents import LlmAgent\n",
    "\n",
    "billing_agent = LlmAgent(name=\"Billing\", description=\"Handles billing inquiries.\")\n",
    "support_agent = LlmAgent(name=\"Support\", description=\"Handles technical support requests.\")\n",
    "\n",
    "coordinator = LlmAgent(\n",
    "    name=\"HelpDeskCoordinator\",\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    instruction=\"Route user requests: Use Billing agent for payment issues, Support agent for technical problems.\",\n",
    "    description=\"Main help desk router.\",\n",
    "    # allow_transfer=True is often implicit with sub_agents in AutoFlow\n",
    "    sub_agents=[billing_agent, support_agent]\n",
    ")\n",
    "# User asks \"My payment failed\" -> Coordinator's LLM should call transfer_to_agent(agent_name='Billing')\n",
    "# User asks \"I can't log in\" -> Coordinator's LLM should call transfer_to_agent(agent_name='Support')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73e11ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conceptual Code: Sequential Data Pipeline\n",
    "from google.adk.agents import SequentialAgent, LlmAgent\n",
    "\n",
    "validator = LlmAgent(name=\"ValidateInput\", instruction=\"Validate the input.\", output_key=\"validation_status\")\n",
    "processor = LlmAgent(name=\"ProcessData\", instruction=\"Process data if {validation_status} is 'valid'.\", output_key=\"result\")\n",
    "reporter = LlmAgent(name=\"ReportResult\", instruction=\"Report the result from {result}.\")\n",
    "\n",
    "data_pipeline = SequentialAgent(\n",
    "    name=\"DataPipeline\",\n",
    "    sub_agents=[validator, processor, reporter]\n",
    ")\n",
    "# validator runs -> saves to state['validation_status']\n",
    "# processor runs -> reads state['validation_status'], saves to state['result']\n",
    "# reporter runs -> reads state['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4dca804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conceptual Code: Parallel Information Gathering\n",
    "from google.adk.agents import SequentialAgent, ParallelAgent, LlmAgent\n",
    "\n",
    "fetch_api1 = LlmAgent(name=\"API1Fetcher\", instruction=\"Fetch data from API 1.\", output_key=\"api1_data\")\n",
    "fetch_api2 = LlmAgent(name=\"API2Fetcher\", instruction=\"Fetch data from API 2.\", output_key=\"api2_data\")\n",
    "\n",
    "gather_concurrently = ParallelAgent(\n",
    "    name=\"ConcurrentFetch\",\n",
    "    sub_agents=[fetch_api1, fetch_api2]\n",
    ")\n",
    "\n",
    "synthesizer = LlmAgent(\n",
    "    name=\"Synthesizer\",\n",
    "    instruction=\"Combine results from {api1_data} and {api2_data}.\"\n",
    ")\n",
    "\n",
    "overall_workflow = SequentialAgent(\n",
    "    name=\"FetchAndSynthesize\",\n",
    "    sub_agents=[gather_concurrently, synthesizer] # Run parallel fetch, then synthesize\n",
    ")\n",
    "# fetch_api1 and fetch_api2 run concurrently, saving to state.\n",
    "# synthesizer runs afterwards, reading state['api1_data'] and state['api2_data']."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b66a9ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conceptual Code: Hierarchical Research Task\n",
    "from google.adk.agents import LlmAgent\n",
    "from google.adk.tools import agent_tool\n",
    "\n",
    "# Low-level tool-like agents\n",
    "web_searcher = LlmAgent(name=\"WebSearch\", description=\"Performs web searches for facts.\")\n",
    "summarizer = LlmAgent(name=\"Summarizer\", description=\"Summarizes text.\")\n",
    "\n",
    "# Mid-level agent combining tools\n",
    "research_assistant = LlmAgent(\n",
    "    name=\"ResearchAssistant\",\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    description=\"Finds and summarizes information on a topic.\",\n",
    "    tools=[agent_tool.AgentTool(agent=web_searcher), agent_tool.AgentTool(agent=summarizer)]\n",
    ")\n",
    "\n",
    "# High-level agent delegating research\n",
    "report_writer = LlmAgent(\n",
    "    name=\"ReportWriter\",\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    instruction=\"Write a report on topic X. Use the ResearchAssistant to gather information.\",\n",
    "    tools=[agent_tool.AgentTool(agent=research_assistant)]\n",
    "    # Alternatively, could use LLM Transfer if research_assistant is a sub_agent\n",
    ")\n",
    "# User interacts with ReportWriter.\n",
    "# ReportWriter calls ResearchAssistant tool.\n",
    "# ResearchAssistant calls WebSearch and Summarizer tools.\n",
    "# Results flow back up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6038b7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conceptual Code: Generator-Critic\n",
    "from google.adk.agents import SequentialAgent, LlmAgent\n",
    "\n",
    "generator = LlmAgent(\n",
    "    name=\"DraftWriter\",\n",
    "    instruction=\"Write a short paragraph about subject X.\",\n",
    "    output_key=\"draft_text\"\n",
    ")\n",
    "\n",
    "reviewer = LlmAgent(\n",
    "    name=\"FactChecker\",\n",
    "    instruction=\"Review the text in {draft_text} for factual accuracy. Output 'valid' or 'invalid' with reasons.\",\n",
    "    output_key=\"review_status\"\n",
    ")\n",
    "\n",
    "# Optional: Further steps based on review_status\n",
    "\n",
    "review_pipeline = SequentialAgent(\n",
    "    name=\"WriteAndReview\",\n",
    "    sub_agents=[generator, reviewer]\n",
    ")\n",
    "# generator runs -> saves draft to state['draft_text']\n",
    "# reviewer runs -> reads state['draft_text'], saves status to state['review_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5dd3ac53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conceptual Code: Iterative Code Refinement\n",
    "from google.adk.agents import LoopAgent, LlmAgent, BaseAgent\n",
    "from google.adk.events import Event, EventActions\n",
    "from google.adk.agents.invocation_context import InvocationContext\n",
    "from typing import AsyncGenerator\n",
    "\n",
    "# Agent to generate/refine code based on state['current_code'] and state['requirements']\n",
    "code_refiner = LlmAgent(\n",
    "    name=\"CodeRefiner\",\n",
    "    instruction=\"Read state['current_code'] (if exists) and state['requirements']. Generate/refine Python code to meet requirements. Save to state['current_code'].\",\n",
    "    output_key=\"current_code\" # Overwrites previous code in state\n",
    ")\n",
    "\n",
    "# Agent to check if the code meets quality standards\n",
    "quality_checker = LlmAgent(\n",
    "    name=\"QualityChecker\",\n",
    "    instruction=\"Evaluate the code in state['current_code'] against state['requirements']. Output 'pass' or 'fail'.\",\n",
    "    output_key=\"quality_status\"\n",
    ")\n",
    "\n",
    "# Custom agent to check the status and escalate if 'pass'\n",
    "class CheckStatusAndEscalate(BaseAgent):\n",
    "    async def _run_async_impl(self, ctx: InvocationContext) -> AsyncGenerator[Event, None]:\n",
    "        status = ctx.session.state.get(\"quality_status\", \"fail\")\n",
    "        should_stop = (status == \"pass\")\n",
    "        yield Event(author=self.name, actions=EventActions(escalate=should_stop))\n",
    "\n",
    "refinement_loop = LoopAgent(\n",
    "    name=\"CodeRefinementLoop\",\n",
    "    max_iterations=5,\n",
    "    sub_agents=[code_refiner, quality_checker, CheckStatusAndEscalate(name=\"StopChecker\")]\n",
    ")\n",
    "# Loop runs: Refiner -> Checker -> StopChecker\n",
    "# State['current_code'] is updated each iteration.\n",
    "# Loop stops if QualityChecker outputs 'pass' (leading to StopChecker escalating) or after 5 iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a647ca",
   "metadata": {},
   "source": [
    "## Human in the loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903b4a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conceptual Code: Using a Tool for Human Approval\n",
    "from google.adk.agents import LlmAgent, SequentialAgent\n",
    "from google.adk.tools import FunctionTool\n",
    "\n",
    "# --- Assume external_approval_tool exists ---\n",
    "# This tool would:\n",
    "# 1. Take details (e.g., request_id, amount, reason).\n",
    "# 2. Send these details to a human review system (e.g., via API).\n",
    "# 3. Poll or wait for the human response (approved/rejected).\n",
    "# 4. Return the human's decision.\n",
    "# async def external_approval_tool(amount: float, reason: str) -> str: ...\n",
    "approval_tool = FunctionTool(func=external_approval_tool)\n",
    "\n",
    "# Agent that prepares the request\n",
    "prepare_request = LlmAgent(\n",
    "    name=\"PrepareApproval\",\n",
    "    instruction=\"Prepare the approval request details based on user input. Store amount and reason in state.\",\n",
    "    # ... likely sets state['approval_amount'] and state['approval_reason'] ...\n",
    ")\n",
    "\n",
    "# Agent that calls the human approval tool\n",
    "request_approval = LlmAgent(\n",
    "    name=\"RequestHumanApproval\",\n",
    "    instruction=\"Use the external_approval_tool with amount from state['approval_amount'] and reason from state['approval_reason'].\",\n",
    "    tools=[approval_tool],\n",
    "    output_key=\"human_decision\"\n",
    ")\n",
    "\n",
    "# Agent that proceeds based on human decision\n",
    "process_decision = LlmAgent(\n",
    "    name=\"ProcessDecision\",\n",
    "    instruction=\"Check {human_decision}. If 'approved', proceed. If 'rejected', inform user.\"\n",
    ")\n",
    "\n",
    "approval_workflow = SequentialAgent(\n",
    "    name=\"HumanApprovalWorkflow\",\n",
    "    sub_agents=[prepare_request, request_approval, process_decision]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
