{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19d82817",
   "metadata": {},
   "source": [
    "# Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1327be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported.\n"
     ]
    }
   ],
   "source": [
    "# @title Import necessary libraries\n",
    "import os\n",
    "import asyncio\n",
    "from google.adk.agents import Agent\n",
    "from google.adk.models.lite_llm import LiteLlm # For multi-model support\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.runners import Runner\n",
    "from google.genai import types # For creating message Content/Parts\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "load_dotenv(override=True)\n",
    "print(\"Libraries imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c114d17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Keys Set:\n",
      "Google API Key set: Yes\n",
      "AzureOpenAI API Key set: Yes\n",
      "Anthropic API Key set: No (REPLACE PLACEHOLDER!)\n"
     ]
    }
   ],
   "source": [
    "# --- Verify Keys (Optional Check) ---\n",
    "print(\"API Keys Set:\")\n",
    "print(f\"Google API Key set: {'Yes' if os.environ.get('GOOGLE_API_KEY') and os.environ['GOOGLE_API_KEY'] != 'YOUR_GOOGLE_API_KEY' else 'No (REPLACE PLACEHOLDER!)'}\")\n",
    "print(f\"AzureOpenAI API Key set: {'Yes' if os.environ.get('AZURE_API_KEY') and os.environ['AZURE_API_KEY'] != 'YOUR_AZURE_API_KEY' else 'No (REPLACE PLACEHOLDER!)'}\")\n",
    "print(f\"Anthropic API Key set: {'Yes' if os.environ.get('ANTHROPIC_API_KEY') and os.environ['ANTHROPIC_API_KEY'] != 'YOUR_ANTHROPIC_API_KEY' else 'No (REPLACE PLACEHOLDER!)'}\")\n",
    "\n",
    "# Configure ADK to use API keys directly (not Vertex AI for this multi-model setup)\n",
    "os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"False\"\n",
    "\n",
    "\n",
    "# @markdown **Security Note:** It's best practice to manage API keys securely (e.g., using Colab Secrets or environment variables) rather than hardcoding them directly in the notebook. Replace the placeholder strings above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "75e07c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Environment configured.\n"
     ]
    }
   ],
   "source": [
    "# --- Define Model Constants for easier use ---\n",
    "\n",
    "# More supported models can be referenced here: https://ai.google.dev/gemini-api/docs/models#model-variations\n",
    "MODEL_GEMINI_2_5_PRO = \"gemini-2.5-pro\"\n",
    "\n",
    "# More supported models can be referenced here: https://docs.litellm.ai/docs/providers/openai#openai-chat-completion-models\n",
    "MODEL_GPT_4O_MINI = \"azure/gpt-4o-mini\" # You can also try: gpt-4.1-mini, gpt-4o etc.\n",
    "\n",
    "# More supported models can be referenced here: https://docs.litellm.ai/docs/providers/anthropic\n",
    "MODEL_CLAUDE_SONNET = \"anthropic/claude-sonnet-4-20250514\" # You can also try: claude-opus-4-20250514 , claude-3-7-sonnet-20250219 etc\n",
    "\n",
    "print(\"\\nEnvironment configured.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc585c9",
   "metadata": {},
   "source": [
    "# Step 1 : Your First Agent - Basic Weather Lookup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05339386",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "Docstring (description) -> Best Practice like in the below. So there are description, arguments, and returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83cc274e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Tool: get_weather called for city: New York ---\n",
      "{'status': 'success', 'report': 'The weather in New York is sunny with a temperature of 25°C.'}\n",
      "--- Tool: get_weather called for city: Paris ---\n",
      "{'status': 'error', 'error_message': \"Sorry, I don't have weather information for 'Paris'.\"}\n"
     ]
    }
   ],
   "source": [
    "# @title Define the get_weather Tool\n",
    "def get_weather(city: str) -> dict:\n",
    "    \"\"\"Retrieves the current weather report for a specified city.\n",
    "\n",
    "    Args:\n",
    "        city (str): The name of the city (e.g., \"New York\", \"London\", \"Tokyo\").\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the weather information.\n",
    "              Includes a 'status' key ('success' or 'error').\n",
    "              If 'success', includes a 'report' key with weather details.\n",
    "              If 'error', includes an 'error_message' key.\n",
    "    \"\"\"\n",
    "    print(f\"--- Tool: get_weather called for city: {city} ---\") # Log tool execution\n",
    "    city_normalized = city.lower().replace(\" \", \"\") # Basic normalization\n",
    "\n",
    "    # Mock weather data\n",
    "    mock_weather_db = {\n",
    "        \"newyork\": {\"status\": \"success\", \"report\": \"The weather in New York is sunny with a temperature of 25°C.\"},\n",
    "        \"london\": {\"status\": \"success\", \"report\": \"It's cloudy in London with a temperature of 15°C.\"},\n",
    "        \"tokyo\": {\"status\": \"success\", \"report\": \"Tokyo is experiencing light rain and a temperature of 18°C.\"},\n",
    "    }\n",
    "\n",
    "    if city_normalized in mock_weather_db:\n",
    "        return mock_weather_db[city_normalized]\n",
    "    else:\n",
    "        return {\"status\": \"error\", \"error_message\": f\"Sorry, I don't have weather information for '{city}'.\"}\n",
    "\n",
    "# Example tool usage (optional test)\n",
    "print(get_weather(\"New York\"))\n",
    "print(get_weather(\"Paris\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6784f484",
   "metadata": {},
   "source": [
    "## Agent\n",
    "\n",
    "Best practice for the agent mmust provide the specific information in the prompt. So the LLM can understand easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e3ef514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent 'weather_agent_v1' created using model 'gemini-2.5-pro'.\n"
     ]
    }
   ],
   "source": [
    "# @title Define the Weather Agent\n",
    "# Use one of the model constants defined earlier\n",
    "AGENT_MODEL = MODEL_GEMINI_2_5_PRO # Starting with Gemini\n",
    "\n",
    "weather_agent = Agent(\n",
    "    name=\"weather_agent_v1\",\n",
    "    model=AGENT_MODEL, # Can be a string for Gemini or a LiteLlm object\n",
    "    description=\"Provides weather information for specific cities.\",\n",
    "    instruction=\"You are a helpful weather assistant. \"\n",
    "                \"When the user asks for the weather in a specific city, \"\n",
    "                \"use the 'get_weather' tool to find the information. \"\n",
    "                \"If the tool returns an error, inform the user politely. \"\n",
    "                \"If the tool is successful, present the weather report clearly.\",\n",
    "    tools=[get_weather], # Pass the function directly\n",
    ")\n",
    "\n",
    "print(f\"Agent '{weather_agent.name}' created using model '{AGENT_MODEL}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe45bd0b",
   "metadata": {},
   "source": [
    "## Session and Run\n",
    "\n",
    "- SessionService: Manage the history and state for different users and sessions\n",
    "- Runner: The engine that orchestrates in the interaction flow. Manages call, logic, tools, and yield the progress "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed2622bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session created: App='weather_tutorial_app', User='user_1', Session='session_001'\n",
      "Runner created for agent 'weather_agent_v1'.\n"
     ]
    }
   ],
   "source": [
    "# @title Setup Session Service and Runner\n",
    "\n",
    "# --- Session Management ---\n",
    "# Key Concept: SessionService stores conversation history & state.\n",
    "# InMemorySessionService is simple, non-persistent storage for this tutorial.\n",
    "session_service = InMemorySessionService()\n",
    "\n",
    "# Define constants for identifying the interaction context\n",
    "APP_NAME = \"weather_tutorial_app\"\n",
    "USER_ID = \"user_1\"\n",
    "SESSION_ID = \"session_001\" # Using a fixed ID for simplicity\n",
    "\n",
    "# Create the specific session where the conversation will happen\n",
    "session = await session_service.create_session(\n",
    "    app_name=APP_NAME,\n",
    "    user_id=USER_ID,\n",
    "    session_id=SESSION_ID\n",
    ")\n",
    "print(f\"Session created: App='{APP_NAME}', User='{USER_ID}', Session='{SESSION_ID}'\")\n",
    "\n",
    "# --- Runner ---\n",
    "# Key Concept: Runner orchestrates the agent execution loop.\n",
    "runner = Runner(\n",
    "    agent=weather_agent, # The agent we want to run\n",
    "    app_name=APP_NAME,   # Associates runs with our app\n",
    "    session_service=session_service # Uses our session manager\n",
    ")\n",
    "print(f\"Runner created for agent '{runner.agent.name}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f8f6df",
   "metadata": {},
   "source": [
    "## Interact\n",
    "\n",
    "Usually interact with the agent use the Async"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bef38d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Define Agent Interaction Function\n",
    "\n",
    "from google.genai import types # For creating message Content/Parts\n",
    "\n",
    "async def call_agent_async(query: str, runner, user_id, session_id):\n",
    "  \"\"\"Sends a query to the agent and prints the final response.\"\"\"\n",
    "  print(f\"\\n>>> User Query: {query}\")\n",
    "\n",
    "  # Prepare the user's message in ADK format\n",
    "  content = types.Content(role='user', parts=[types.Part(text=query)])\n",
    "  # print(\"Content\", content)\n",
    "\n",
    "  final_response_text = \"Agent did not produce a final response.\" # Default\n",
    "\n",
    "  # Key Concept: run_async executes the agent logic and yields Events.\n",
    "  # We iterate through events to find the final answer.\n",
    "  async for event in runner.run_async(user_id=user_id, session_id=session_id, new_message=content):\n",
    "      # You can uncomment the line below to see *all* events during execution\n",
    "      # print(f\"  [Event] Author: {event.author}, Type: {type(event).__name__}, Final: {event.is_final_response()}, Content: {event.content}\")\n",
    "\n",
    "      # Key Concept: is_final_response() marks the concluding message for the turn.\n",
    "      if event.is_final_response():\n",
    "          # print(\"Event\", event)\n",
    "          if event.content and event.content.parts:\n",
    "             # Assuming text response in the first part\n",
    "            final_response_text = event.content.parts[0].text\n",
    "            # print(\"Final Response\", final_response_text)\n",
    "          elif event.actions and event.actions.escalate: # Handle potential errors/escalations\n",
    "            final_response_text = f\"Agent escalated: {event.error_message or 'No specific message.'}\"\n",
    "            # print(\"Final Response\", final_response_text)\n",
    "          # Add more checks here if needed (e.g., specific error codes)\n",
    "          break # Stop processing events once the final response is found\n",
    "\n",
    "  print(f\"<<< Agent Response: {final_response_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6dc59ab",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8d29dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> User Query: What is the weather like in London?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:asyncio:Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x71df825ba660>\n",
      "ERROR:asyncio:Unclosed connector\n",
      "connections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x71df825a3dd0>, 4268.650998928)])']\n",
      "connector: <aiohttp.connector.TCPConnector object at 0x71df825b9be0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Tool: get_weather called for city: London ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:asyncio:Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x71df825bba10>\n",
      "ERROR:asyncio:Unclosed connector\n",
      "connections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x71df825a3dd0>, 4273.361756477)])']\n",
      "connector: <aiohttp.connector.TCPConnector object at 0x71df825bb950>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< Agent Response: It's cloudy in London with a temperature of 15°C.\n",
      "\n",
      ">>> User Query: How about Paris?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:asyncio:Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x71df8264c5f0>\n",
      "ERROR:asyncio:Unclosed connector\n",
      "connections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x71df825a3dd0>, 4276.297849576)])']\n",
      "connector: <aiohttp.connector.TCPConnector object at 0x71df8264c530>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Tool: get_weather called for city: Paris ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:asyncio:Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x71df825ba990>\n",
      "ERROR:asyncio:Unclosed connector\n",
      "connections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x71df825a3c50>, 4278.179707879)])']\n",
      "connector: <aiohttp.connector.TCPConnector object at 0x71df825bade0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< Agent Response: Sorry, I don't have weather information for Paris.\n",
      "\n",
      ">>> User Query: Tell me the weather in New York\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:asyncio:Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x71df8264cc20>\n",
      "ERROR:asyncio:Unclosed connector\n",
      "connections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x71df82604710>, 4282.279695104)])']\n",
      "connector: <aiohttp.connector.TCPConnector object at 0x71df825bae70>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Tool: get_weather called for city: New York ---\n",
      "<<< Agent Response: The weather in New York is sunny with a temperature of 25°C.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:asyncio:Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x71df8264cb60>\n",
      "ERROR:asyncio:Unclosed connector\n",
      "connections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x71df82604710>, 4285.660174325)])']\n",
      "connector: <aiohttp.connector.TCPConnector object at 0x71df825b9df0>\n"
     ]
    }
   ],
   "source": [
    "# @title Run the Initial Conversation\n",
    "\n",
    "# We need an async function to await our interaction helper\n",
    "async def run_conversation():\n",
    "    await call_agent_async(\"What is the weather like in London?\",\n",
    "                                       runner=runner,\n",
    "                                       user_id=USER_ID,\n",
    "                                       session_id=SESSION_ID)\n",
    "\n",
    "    await call_agent_async(\"How about Paris?\",\n",
    "                                       runner=runner,\n",
    "                                       user_id=USER_ID,\n",
    "                                       session_id=SESSION_ID) # Expecting the tool's error message\n",
    "\n",
    "    await call_agent_async(\"Tell me the weather in New York\",\n",
    "                                       runner=runner,\n",
    "                                       user_id=USER_ID,\n",
    "                                       session_id=SESSION_ID)\n",
    "\n",
    "# Execute the conversation using await in an async context (like Colab/Jupyter)\n",
    "await run_conversation()\n",
    "\n",
    "# --- OR ---\n",
    "\n",
    "# Uncomment the following lines if running as a standard Python script (.py file):\n",
    "# import asyncio\n",
    "# if __name__ == \"__main__\":\n",
    "#     try:\n",
    "#         asyncio.run(run_conversation())\n",
    "#     except Exception as e:\n",
    "#         print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbb1b812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> User Query: What is the weather like in London?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:asyncio:Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x71df8264c740>\n",
      "ERROR:asyncio:Unclosed connector\n",
      "connections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x71df825a3fb0>, 4289.467681164)])']\n",
      "connector: <aiohttp.connector.TCPConnector object at 0x71df8264cb90>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Tool: get_weather called for city: London ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:asyncio:Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x71df8264c800>\n",
      "ERROR:asyncio:Unclosed connector\n",
      "connections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x71df82604410>, 4291.707111989)])']\n",
      "connector: <aiohttp.connector.TCPConnector object at 0x71df8264c5f0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< Agent Response: It's cloudy in London with a temperature of 15°C.\n",
      "\n",
      ">>> User Query: How about Paris?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:asyncio:Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x71df8264d6a0>\n",
      "ERROR:asyncio:Unclosed connector\n",
      "connections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x71df825a3c50>, 4297.037723528)])']\n",
      "connector: <aiohttp.connector.TCPConnector object at 0x71df8264d5e0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Tool: get_weather called for city: Paris ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:asyncio:Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x71df8264d820>\n",
      "ERROR:asyncio:Unclosed connector\n",
      "connections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x71df825a3c50>, 4299.067935023)])']\n",
      "connector: <aiohttp.connector.TCPConnector object at 0x71df825b9a30>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< Agent Response: Sorry, I don't have weather information for Paris.\n",
      "\n",
      ">>> User Query: Tell me the weather in New York\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:asyncio:Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x71df8264dbe0>\n",
      "ERROR:asyncio:Unclosed connector\n",
      "connections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x71df825a3c50>, 4301.646621153)])']\n",
      "connector: <aiohttp.connector.TCPConnector object at 0x71df8264c980>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Tool: get_weather called for city: New York ---\n",
      "<<< Agent Response: The weather in New York is sunny with a temperature of 25°C.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:asyncio:Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x71df8264df70>\n",
      "ERROR:asyncio:Unclosed connector\n",
      "connections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x71df825a3c50>, 4303.391618519)])']\n",
      "connector: <aiohttp.connector.TCPConnector object at 0x71df8264c8f0>\n"
     ]
    }
   ],
   "source": [
    "await run_conversation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863d89c5",
   "metadata": {},
   "source": [
    "# Step 2: Going Multi-Model with LiteLLM [Optional]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e9d276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent 'weather_agent_gpt' created using model 'azure/gpt-4o-mini'.\n",
      "Session created: App='weather_tutorial_app_gpt', User='user_1_gpt', Session='session_001_gpt'\n",
      "Runner created for agent 'weather_agent_gpt'.\n",
      "\n",
      "--- Testing GPT Agent ---\n",
      "\n",
      ">>> User Query: What's the weather in Tokyo?\n",
      "--- Tool: get_weather called for city: Tokyo ---\n",
      "<<< Agent Response: The weather in Tokyo is currently light rain with a temperature of 18°C.\n"
     ]
    }
   ],
   "source": [
    "# @title Define and Test GPT Agent\n",
    "\n",
    "# Make sure 'get_weather' function from Step 1 is defined in your environment.\n",
    "# Make sure 'call_agent_async' is defined from earlier.\n",
    "\n",
    "# --- Agent using GPT-4o ---\n",
    "weather_agent_gpt = None # Initialize to None\n",
    "runner_gpt = None      # Initialize runner to None\n",
    "\n",
    "try:\n",
    "    weather_agent_gpt = Agent(\n",
    "        name=\"weather_agent_gpt\",\n",
    "        # Key change: Wrap the LiteLLM model identifier\n",
    "        model=LiteLlm(model=MODEL_GPT_4O_MINI),\n",
    "        description=\"Provides weather information (using GPT-4o-mini).\",\n",
    "        instruction=\"You are a helpful weather assistant powered by GPT-4o-mini. \"\n",
    "                    \"Use the 'get_weather' tool for city weather requests. \"\n",
    "                    \"Clearly present successful reports or polite error messages based on the tool's output status.\",\n",
    "        tools=[get_weather], # Re-use the same tool\n",
    "    )\n",
    "    print(f\"Agent '{weather_agent_gpt.name}' created using model '{MODEL_GPT_4O_MINI}'.\")\n",
    "\n",
    "    # InMemorySessionService is simple, non-persistent storage for this tutorial.\n",
    "    session_service_gpt = InMemorySessionService() # Create a dedicated service\n",
    "\n",
    "    # Define constants for identifying the interaction context\n",
    "    APP_NAME_GPT = \"weather_tutorial_app_gpt\" # Unique app name for this test\n",
    "    USER_ID_GPT = \"user_1_gpt\"\n",
    "    SESSION_ID_GPT = \"session_001_gpt\" # Using a fixed ID for simplicity\n",
    "\n",
    "    # Create the specific session where the conversation will happen\n",
    "    session_gpt = await session_service_gpt.create_session(\n",
    "        app_name=APP_NAME_GPT,\n",
    "        user_id=USER_ID_GPT,\n",
    "        session_id=SESSION_ID_GPT\n",
    "    )\n",
    "    print(f\"Session created: App='{APP_NAME_GPT}', User='{USER_ID_GPT}', Session='{SESSION_ID_GPT}'\")\n",
    "\n",
    "    # Create a runner specific to this agent and its session service\n",
    "    runner_gpt = Runner(\n",
    "        agent=weather_agent_gpt,\n",
    "        app_name=APP_NAME_GPT,       # Use the specific app name\n",
    "        session_service=session_service_gpt # Use the specific session service\n",
    "        )\n",
    "    print(f\"Runner created for agent '{runner_gpt.agent.name}'.\")\n",
    "\n",
    "    # --- Test the GPT Agent ---\n",
    "    print(\"\\n--- Testing GPT Agent ---\")\n",
    "    # Ensure call_agent_async uses the correct runner, user_id, session_id\n",
    "    await call_agent_async(query = \"What's the weather in Tokyo?\",\n",
    "                           runner=runner_gpt,\n",
    "                           user_id=USER_ID_GPT,\n",
    "                           session_id=SESSION_ID_GPT)\n",
    "    # --- OR ---\n",
    "\n",
    "    # Uncomment the following lines if running as a standard Python script (.py file):\n",
    "    # import asyncio\n",
    "    # if __name__ == \"__main__\":\n",
    "    #     try:\n",
    "    #         asyncio.run(call_agent_async(query = \"What's the weather in Tokyo?\",\n",
    "    #                      runner=runner_gpt,\n",
    "    #                       user_id=USER_ID_GPT,\n",
    "    #                       session_id=SESSION_ID_GPT)\n",
    "    #     except Exception as e:\n",
    "    #         print(f\"An error occurred: {e}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Could not create or run GPT agent '{MODEL_GPT_4O_MINI}'. Check API Key and model name. Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8bcc48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> User Query: What's the weather in Rengat?\n",
      "--- Tool: get_weather called for city: Rengat ---\n",
      "<<< Agent Response: I'm sorry, but I don't have weather information for Rengat.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/agrelvin8135@corp.ai.astra.co.id/Documents/Data/UdemyProject/Agentic-AI/.venv/lib/python3.12/site-packages/zmq/eventloop/zmqstream.py\", line 565, in _log_error\n",
      "    f.result()\n",
      "  File \"/home/agrelvin8135@corp.ai.astra.co.id/Documents/Data/UdemyProject/Agentic-AI/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 302, in dispatch_control\n",
      "    await self.process_control(msg)\n",
      "  File \"/home/agrelvin8135@corp.ai.astra.co.id/Documents/Data/UdemyProject/Agentic-AI/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 308, in process_control\n",
      "    idents, msg = self.session.feed_identities(msg, copy=False)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/agrelvin8135@corp.ai.astra.co.id/Documents/Data/UdemyProject/Agentic-AI/.venv/lib/python3.12/site-packages/jupyter_client/session.py\", line 994, in feed_identities\n",
      "    raise ValueError(msg)\n",
      "ValueError: DELIM not in msg_list\n",
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/agrelvin8135@corp.ai.astra.co.id/Documents/Data/UdemyProject/Agentic-AI/.venv/lib/python3.12/site-packages/zmq/eventloop/zmqstream.py\", line 565, in _log_error\n",
      "    f.result()\n",
      "  File \"/home/agrelvin8135@corp.ai.astra.co.id/Documents/Data/UdemyProject/Agentic-AI/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 302, in dispatch_control\n",
      "    await self.process_control(msg)\n",
      "  File \"/home/agrelvin8135@corp.ai.astra.co.id/Documents/Data/UdemyProject/Agentic-AI/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 308, in process_control\n",
      "    idents, msg = self.session.feed_identities(msg, copy=False)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/agrelvin8135@corp.ai.astra.co.id/Documents/Data/UdemyProject/Agentic-AI/.venv/lib/python3.12/site-packages/jupyter_client/session.py\", line 994, in feed_identities\n",
      "    raise ValueError(msg)\n",
      "ValueError: DELIM not in msg_list\n",
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/agrelvin8135@corp.ai.astra.co.id/Documents/Data/UdemyProject/Agentic-AI/.venv/lib/python3.12/site-packages/zmq/eventloop/zmqstream.py\", line 565, in _log_error\n",
      "    f.result()\n",
      "  File \"/home/agrelvin8135@corp.ai.astra.co.id/Documents/Data/UdemyProject/Agentic-AI/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 302, in dispatch_control\n",
      "    await self.process_control(msg)\n",
      "  File \"/home/agrelvin8135@corp.ai.astra.co.id/Documents/Data/UdemyProject/Agentic-AI/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 308, in process_control\n",
      "    idents, msg = self.session.feed_identities(msg, copy=False)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/agrelvin8135@corp.ai.astra.co.id/Documents/Data/UdemyProject/Agentic-AI/.venv/lib/python3.12/site-packages/jupyter_client/session.py\", line 994, in feed_identities\n",
      "    raise ValueError(msg)\n",
      "ValueError: DELIM not in msg_list\n",
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/agrelvin8135@corp.ai.astra.co.id/Documents/Data/UdemyProject/Agentic-AI/.venv/lib/python3.12/site-packages/zmq/eventloop/zmqstream.py\", line 565, in _log_error\n",
      "    f.result()\n",
      "  File \"/home/agrelvin8135@corp.ai.astra.co.id/Documents/Data/UdemyProject/Agentic-AI/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 302, in dispatch_control\n",
      "    await self.process_control(msg)\n",
      "  File \"/home/agrelvin8135@corp.ai.astra.co.id/Documents/Data/UdemyProject/Agentic-AI/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 308, in process_control\n",
      "    idents, msg = self.session.feed_identities(msg, copy=False)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/agrelvin8135@corp.ai.astra.co.id/Documents/Data/UdemyProject/Agentic-AI/.venv/lib/python3.12/site-packages/jupyter_client/session.py\", line 994, in feed_identities\n",
      "    raise ValueError(msg)\n",
      "ValueError: DELIM not in msg_list\n",
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/agrelvin8135@corp.ai.astra.co.id/Documents/Data/UdemyProject/Agentic-AI/.venv/lib/python3.12/site-packages/zmq/eventloop/zmqstream.py\", line 565, in _log_error\n",
      "    f.result()\n",
      "  File \"/home/agrelvin8135@corp.ai.astra.co.id/Documents/Data/UdemyProject/Agentic-AI/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 302, in dispatch_control\n",
      "    await self.process_control(msg)\n",
      "  File \"/home/agrelvin8135@corp.ai.astra.co.id/Documents/Data/UdemyProject/Agentic-AI/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 308, in process_control\n",
      "    idents, msg = self.session.feed_identities(msg, copy=False)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/agrelvin8135@corp.ai.astra.co.id/Documents/Data/UdemyProject/Agentic-AI/.venv/lib/python3.12/site-packages/jupyter_client/session.py\", line 994, in feed_identities\n",
      "    raise ValueError(msg)\n",
      "ValueError: DELIM not in msg_list\n",
      "Bad pipe message: %s [b'\\x95\\x17w\\xa0\\xc23\\x85\\xae\\xad\\xba\\xffGz\\x9a\\x95B\\x1f\\xab\\x00\\x01|\\x00\\x00\\x00\\x01\\x00\\x02\\x00\\x03\\x00\\x04\\x00\\x05\\x00\\x06\\x00\\x07\\x00\\x08\\x00\\t\\x00\\n\\x00\\x0b\\x00\\x0c\\x00\\r\\x00\\x0e\\x00\\x0f\\x00\\x10\\x00\\x11\\x00\\x12\\x00\\x13\\x00\\x14\\x00\\x15\\x00\\x16\\x00\\x17\\x00\\x18\\x00\\x19\\x00\\x1a\\x00\\x1b\\x00/\\x000\\x001\\x002\\x003\\x004\\x005\\x006\\x007\\x008\\x009\\x00:\\x00;\\x00<\\x00=\\x00>\\x00?\\x00@\\x00A\\x00B\\x00C\\x00D\\x00E\\x00F\\x00g\\x00h\\x00i\\x00j\\x00k\\x00l\\x00m\\x00\\x84\\x00\\x85\\x00\\x86\\x00\\x87\\x00\\x88\\x00\\x89\\x00\\x96\\x00\\x97\\x00\\x98\\x00\\x99\\x00\\x9a\\x00\\x9b\\x00\\x9c\\x00\\x9d\\x00\\x9e\\x00\\x9f\\x00\\xa0\\x00\\xa1\\x00\\xa2\\x00\\xa3\\x00\\xa4\\x00\\xa5\\x00\\xa6\\x00\\xa7\\x00\\xba\\x00\\xbb\\x00\\xbc\\x00\\xbd\\x00\\xbe\\x00\\xbf\\x00\\xc0\\x00\\xc1\\x00\\xc2\\x00\\xc3\\x00\\xc4\\x00\\xc5\\x13\\x01\\x13\\x02\\x13\\x03\\x13\\x04\\x13\\x05']\n",
      "Bad pipe message: %s [b'Y\\x07\\xef\\x8a\\xa1\\x06\\xc7b\\x97L|\\x99p]\\xc9o\\x8ef\\x00\\x01|\\x00\\x00\\x00\\x01\\x00\\x02\\x00\\x03\\x00\\x04\\x00\\x05\\x00\\x06\\x00\\x07\\x00\\x08\\x00\\t\\x00\\n\\x00\\x0b\\x00\\x0c\\x00\\r\\x00\\x0e\\x00\\x0f\\x00\\x10\\x00\\x11\\x00\\x12\\x00\\x13\\x00\\x14\\x00\\x15\\x00\\x16\\x00\\x17\\x00\\x18\\x00\\x19\\x00\\x1a\\x00\\x1b\\x00/\\x000\\x001\\x002\\x003\\x004\\x005\\x006\\x007\\x008\\x009\\x00:\\x00;\\x00<\\x00=\\x00>\\x00?\\x00@\\x00A\\x00B\\x00C\\x00D\\x00E\\x00F\\x00g\\x00h\\x00i\\x00j\\x00k\\x00l\\x00m\\x00\\x84\\x00\\x85\\x00\\x86\\x00\\x87\\x00\\x88\\x00\\x89\\x00\\x96\\x00\\x97\\x00\\x98\\x00\\x99\\x00\\x9a\\x00\\x9b\\x00\\x9c\\x00\\x9d\\x00\\x9e\\x00\\x9f\\x00\\xa0\\x00\\xa1\\x00\\xa2\\x00\\xa3\\x00\\xa4\\x00\\xa5\\x00\\xa6\\x00\\xa7\\x00\\xba\\x00\\xbb\\x00\\xbc\\x00\\xbd\\x00\\xbe\\x00\\xbf\\x00\\xc0\\x00\\xc1\\x00\\xc2']\n",
      "Bad pipe message: %s [b'<\\xb6\\xcd\\x8eO\\xb8.=R(\\x91\\xc0r_\\rR;\\x91\\x00\\x01|\\x00\\x00\\x00\\x01\\x00\\x02\\x00\\x03\\x00\\x04\\x00\\x05\\x00\\x06\\x00\\x07\\x00\\x08\\x00\\t\\x00\\n\\x00\\x0b\\x00\\x0c\\x00\\r\\x00\\x0e\\x00\\x0f\\x00\\x10\\x00\\x11\\x00\\x12\\x00\\x13\\x00\\x14\\x00\\x15\\x00\\x16\\x00\\x17\\x00\\x18\\x00\\x19\\x00\\x1a\\x00\\x1b\\x00/\\x000\\x001\\x002\\x003\\x004\\x005\\x006\\x007\\x008\\x009\\x00:\\x00;\\x00<\\x00=\\x00>\\x00?\\x00@\\x00A\\x00B\\x00C\\x00D\\x00E\\x00']\n",
      "Bad pipe message: %s [b'g\\x00h\\x00i\\x00j\\x00k\\x00l\\x00m\\x00\\x84\\x00\\x85\\x00\\x86\\x00\\x87\\x00\\x88\\x00\\x89\\x00\\x96\\x00\\x97\\x00\\x98\\x00\\x99\\x00\\x9a\\x00\\x9b\\x00\\x9c\\x00\\x9d\\x00\\x9e\\x00\\x9f\\x00\\xa0\\x00\\xa1\\x00\\xa2\\x00\\xa3\\x00\\xa4\\x00\\xa5\\x00\\xa6\\x00\\xa7\\x00\\xba\\x00\\xbb\\x00\\xbc\\x00\\xbd']\n",
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/agrelvin8135@corp.ai.astra.co.id/Documents/Data/UdemyProject/Agentic-AI/.venv/lib/python3.12/site-packages/zmq/eventloop/zmqstream.py\", line 565, in _log_error\n",
      "    f.result()\n",
      "  File \"/home/agrelvin8135@corp.ai.astra.co.id/Documents/Data/UdemyProject/Agentic-AI/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 302, in dispatch_control\n",
      "    await self.process_control(msg)\n",
      "  File \"/home/agrelvin8135@corp.ai.astra.co.id/Documents/Data/UdemyProject/Agentic-AI/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 308, in process_control\n",
      "    idents, msg = self.session.feed_identities(msg, copy=False)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/agrelvin8135@corp.ai.astra.co.id/Documents/Data/UdemyProject/Agentic-AI/.venv/lib/python3.12/site-packages/jupyter_client/session.py\", line 994, in feed_identities\n",
      "    raise ValueError(msg)\n",
      "ValueError: DELIM not in msg_list\n",
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/agrelvin8135@corp.ai.astra.co.id/Documents/Data/UdemyProject/Agentic-AI/.venv/lib/python3.12/site-packages/zmq/eventloop/zmqstream.py\", line 565, in _log_error\n",
      "    f.result()\n",
      "  File \"/home/agrelvin8135@corp.ai.astra.co.id/Documents/Data/UdemyProject/Agentic-AI/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 302, in dispatch_control\n",
      "    await self.process_control(msg)\n",
      "  File \"/home/agrelvin8135@corp.ai.astra.co.id/Documents/Data/UdemyProject/Agentic-AI/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 308, in process_control\n",
      "    idents, msg = self.session.feed_identities(msg, copy=False)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/agrelvin8135@corp.ai.astra.co.id/Documents/Data/UdemyProject/Agentic-AI/.venv/lib/python3.12/site-packages/jupyter_client/session.py\", line 994, in feed_identities\n",
      "    raise ValueError(msg)\n",
      "ValueError: DELIM not in msg_list\n",
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/agrelvin8135@corp.ai.astra.co.id/Documents/Data/UdemyProject/Agentic-AI/.venv/lib/python3.12/site-packages/zmq/eventloop/zmqstream.py\", line 565, in _log_error\n",
      "    f.result()\n",
      "  File \"/home/agrelvin8135@corp.ai.astra.co.id/Documents/Data/UdemyProject/Agentic-AI/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 302, in dispatch_control\n",
      "    await self.process_control(msg)\n",
      "  File \"/home/agrelvin8135@corp.ai.astra.co.id/Documents/Data/UdemyProject/Agentic-AI/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 308, in process_control\n",
      "    idents, msg = self.session.feed_identities(msg, copy=False)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/agrelvin8135@corp.ai.astra.co.id/Documents/Data/UdemyProject/Agentic-AI/.venv/lib/python3.12/site-packages/jupyter_client/session.py\", line 994, in feed_identities\n",
      "    raise ValueError(msg)\n",
      "ValueError: DELIM not in msg_list\n"
     ]
    }
   ],
   "source": [
    "await call_agent_async(query = \"What's the weather in Rengat?\",\n",
    "                        runner=runner_gpt,\n",
    "                        user_id=USER_ID_GPT,\n",
    "                        session_id=SESSION_ID_GPT)\n",
    "# --- OR ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f30b099",
   "metadata": {},
   "source": [
    "# Step 3: Building an Agent Team - Delegation for Greetings & Farewells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a51041",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43fa2dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greeting and Farewell tools defined.\n",
      "--- Tool: say_hello called with name: Alice ---\n",
      "Hello, Alice!\n",
      "--- Tool: say_hello called without a specific name (name_arg_value: None) ---\n",
      "Hello there!\n",
      "--- Tool: say_hello called without a specific name (name_arg_value: None) ---\n",
      "Hello there!\n"
     ]
    }
   ],
   "source": [
    "# @title Define Tools for Greeting and Farewell Agents\n",
    "from typing import Optional # Make sure to import Optional\n",
    "\n",
    "# Ensure 'get_weather' from Step 1 is available if running this step independently.\n",
    "# def get_weather(city: str) -> dict: ... (from Step 1)\n",
    "\n",
    "def say_hello(name: Optional[str] = None) -> str:\n",
    "    \"\"\"Provides a simple greeting. If a name is provided, it will be used.\n",
    "\n",
    "    Args:\n",
    "        name (str, optional): The name of the person to greet. Defaults to a generic greeting if not provided.\n",
    "\n",
    "    Returns:\n",
    "        str: A friendly greeting message.\n",
    "    \"\"\"\n",
    "    if name:\n",
    "        greeting = f\"Hello, {name}!\"\n",
    "        print(f\"--- Tool: say_hello called with name: {name} ---\")\n",
    "    else:\n",
    "        greeting = \"Hello there!\" # Default greeting if name is None or not explicitly passed\n",
    "        print(f\"--- Tool: say_hello called without a specific name (name_arg_value: {name}) ---\")\n",
    "    return greeting\n",
    "\n",
    "def say_goodbye() -> str:\n",
    "    \"\"\"Provides a simple farewell message to conclude the conversation.\"\"\"\n",
    "    print(f\"--- Tool: say_goodbye called ---\")\n",
    "    return \"Goodbye! Have a great day.\"\n",
    "\n",
    "print(\"Greeting and Farewell tools defined.\")\n",
    "\n",
    "# Optional self-test\n",
    "print(say_hello(\"Alice\"))\n",
    "print(say_hello()) # Test with no argument (should use default \"Hello there!\")\n",
    "print(say_hello(name=None)) # Test with name explicitly as None (should use default \"Hello there!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7045587c",
   "metadata": {},
   "source": [
    "## Sub-Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7a2ef36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Agent 'greeting_agent' created using model 'model='azure/gpt-4o-mini' llm_client=<google.adk.models.lite_llm.LiteLLMClient object at 0x71df804d3ef0>'.\n",
      "✅ Agent 'farewell_agent' created using model 'gemini-2.5-pro'.\n"
     ]
    }
   ],
   "source": [
    "# @title Define Greeting and Farewell Sub-Agents\n",
    "\n",
    "# If you want to use models other than Gemini, Ensure LiteLlm is imported and API keys are set (from Step 0/2)\n",
    "# from google.adk.models.lite_llm import LiteLlm\n",
    "# MODEL_GPT_4O, MODEL_CLAUDE_SONNET etc. should be defined\n",
    "# Or else, continue to use: model = MODEL_GEMINI_2_0_FLASH\n",
    "\n",
    "# --- Greeting Agent ---\n",
    "greeting_agent = None\n",
    "try:\n",
    "    greeting_agent = Agent(\n",
    "        # Using a potentially different/cheaper model for a simple task\n",
    "        # model = MODEL_GEMINI_2_5_PRO,\n",
    "        model=LiteLlm(model=MODEL_GPT_4O_MINI), # If you would like to experiment with other models\n",
    "        name=\"greeting_agent\",\n",
    "        instruction=\"You are the Greeting Agent. Your ONLY task is to provide a friendly greeting to the user. \"\n",
    "                    \"Use the 'say_hello' tool to generate the greeting. \"\n",
    "                    \"If the user provides their name, make sure to pass it to the tool. \"\n",
    "                    \"Do not engage in any other conversation or tasks.\",\n",
    "        description=\"Handles simple greetings and hellos using the 'say_hello' tool.\", # Crucial for delegation\n",
    "        tools=[say_hello],\n",
    "    )\n",
    "    print(f\"✅ Agent '{greeting_agent.name}' created using model '{greeting_agent.model}'.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Could not create Greeting agent. Check API Key ({greeting_agent.model}). Error: {e}\")\n",
    "\n",
    "# --- Farewell Agent ---\n",
    "farewell_agent = None\n",
    "try:\n",
    "    farewell_agent = Agent(\n",
    "        # Can use the same or a different model\n",
    "        model = MODEL_GEMINI_2_5_PRO,\n",
    "        # model=LiteLlm(model=MODEL_GPT_4O), # If you would like to experiment with other models\n",
    "        name=\"farewell_agent\",\n",
    "        instruction=\"You are the Farewell Agent. Your ONLY task is to provide a polite goodbye message. \"\n",
    "                    \"Use the 'say_goodbye' tool when the user indicates they are leaving or ending the conversation \"\n",
    "                    \"(e.g., using words like 'bye', 'goodbye', 'thanks bye', 'see you'). \"\n",
    "                    \"Do not perform any other actions.\",\n",
    "        description=\"Handles simple farewells and goodbyes using the 'say_goodbye' tool.\", # Crucial for delegation\n",
    "        tools=[say_goodbye],\n",
    "    )\n",
    "    print(f\"✅ Agent '{farewell_agent.name}' created using model '{farewell_agent.model}'.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Could not create Farewell agent. Check API Key ({farewell_agent.model}). Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01c2e22",
   "metadata": {},
   "source": [
    "## Root Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dcfbab5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Root Agent 'weather_agent_v2' created using model 'gemini-2.5-pro' with sub-agents: ['greeting_agent', 'farewell_agent']\n"
     ]
    }
   ],
   "source": [
    "# @title Define the Root Agent with Sub-Agents\n",
    "\n",
    "# Ensure sub-agents were created successfully before defining the root agent.\n",
    "# Also ensure the original 'get_weather' tool is defined.\n",
    "root_agent = None\n",
    "runner_root = None # Initialize runner\n",
    "\n",
    "if greeting_agent and farewell_agent and 'get_weather' in globals():\n",
    "    # Let's use a capable Gemini model for the root agent to handle orchestration\n",
    "    root_agent_model = MODEL_GEMINI_2_5_PRO\n",
    "\n",
    "    weather_agent_team = Agent(\n",
    "        name=\"weather_agent_v2\", # Give it a new version name\n",
    "        model=root_agent_model,\n",
    "        description=\"The main coordinator agent. Handles weather requests and delegates greetings/farewells to specialists.\",\n",
    "        instruction=\"You are the main Weather Agent coordinating a team. Your primary responsibility is to provide weather information. \"\n",
    "                    \"Use the 'get_weather' tool ONLY for specific weather requests (e.g., 'weather in London'). \"\n",
    "                    \"You have specialized sub-agents: \"\n",
    "                    \"1. 'greeting_agent': Handles simple greetings like 'Hi', 'Hello'. Delegate to it for these. \"\n",
    "                    \"2. 'farewell_agent': Handles simple farewells like 'Bye', 'See you'. Delegate to it for these. \"\n",
    "                    \"Analyze the user's query. If it's a greeting, delegate to 'greeting_agent'. If it's a farewell, delegate to 'farewell_agent'. \"\n",
    "                    \"If it's a weather request, handle it yourself using 'get_weather'. \"\n",
    "                    \"For anything else, respond appropriately or state you cannot handle it.\",\n",
    "        tools=[get_weather], # Root agent still needs the weather tool for its core task\n",
    "        # Key change: Link the sub-agents here!\n",
    "        sub_agents=[greeting_agent, farewell_agent]\n",
    "    )\n",
    "    print(f\"✅ Root Agent '{weather_agent_team.name}' created using model '{root_agent_model}' with sub-agents: {[sa.name for sa in weather_agent_team.sub_agents]}\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ Cannot create root agent because one or more sub-agents failed to initialize or 'get_weather' tool is missing.\")\n",
    "    if not greeting_agent: print(\" - Greeting Agent is missing.\")\n",
    "    if not farewell_agent: print(\" - Farewell Agent is missing.\")\n",
    "    if 'get_weather' not in globals(): print(\" - get_weather function is missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2255a32f",
   "metadata": {},
   "source": [
    "## Interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38beb82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting execution using 'await' (default for notebooks)...\n",
      "\n",
      "--- Testing Agent Team Delegation ---\n",
      "Session created: App='weather_tutorial_agent_team', User='user_1_agent_team', Session='session_001_agent_team'\n",
      "Runner created for agent 'weather_agent_v2'.\n",
      "\n",
      ">>> User Query: Hello there!\n",
      "--- Tool: say_hello called without a specific name (name_arg_value: None) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:asyncio:Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x71df804d11f0>\n",
      "ERROR:asyncio:Unclosed connector\n",
      "connections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x71df73f0d670>, 5926.003564287)])']\n",
      "connector: <aiohttp.connector.TCPConnector object at 0x71df804d1ca0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< Agent Response: Hello there!\n",
      "\n",
      ">>> User Query: What is the weather in New York?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:asyncio:Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x71df804ae5d0>\n",
      "ERROR:asyncio:Unclosed connector\n",
      "connections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x71df73fc6930>, 5932.465844579)])']\n",
      "connector: <aiohttp.connector.TCPConnector object at 0x71df804acd70>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Tool: get_weather called for city: New York ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:asyncio:Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x71df804970b0>\n",
      "ERROR:asyncio:Unclosed connector\n",
      "connections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x71df73f0d4f0>, 5934.29755661)])']\n",
      "connector: <aiohttp.connector.TCPConnector object at 0x71df80495b80>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< Agent Response: The weather in New York is sunny with a temperature of 25°C.\n",
      "\n",
      "\n",
      ">>> User Query: Thanks, bye!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:asyncio:Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x71df80497b60>\n",
      "ERROR:asyncio:Unclosed connector\n",
      "connections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x71df73f0cc50>, 5945.474917533)])']\n",
      "connector: <aiohttp.connector.TCPConnector object at 0x71df804973e0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Tool: say_goodbye called ---\n",
      "<<< Agent Response: Goodbye! Have a great day.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:asyncio:Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x71df804d2930>\n",
      "ERROR:asyncio:Unclosed connector\n",
      "connections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x71df73f66bd0>, 5936.858418146)])']\n",
      "connector: <aiohttp.connector.TCPConnector object at 0x71df804d3cb0>\n",
      "ERROR:asyncio:Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x71df804942c0>\n",
      "ERROR:asyncio:Unclosed connector\n",
      "connections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x71df73fc6b10>, 5948.429144562)])']\n",
      "connector: <aiohttp.connector.TCPConnector object at 0x71df80496240>\n"
     ]
    }
   ],
   "source": [
    "# @title Interact with the Agent Team\n",
    "import asyncio # Ensure asyncio is imported\n",
    "\n",
    "# Ensure the root agent (e.g., 'weather_agent_team' or 'root_agent' from the previous cell) is defined.\n",
    "# Ensure the call_agent_async function is defined.\n",
    "\n",
    "# Check if the root agent variable exists before defining the conversation function\n",
    "root_agent_var_name = 'root_agent' # Default name from Step 3 guide\n",
    "if 'weather_agent_team' in globals(): # Check if user used this name instead\n",
    "    root_agent_var_name = 'weather_agent_team'\n",
    "elif 'root_agent' not in globals():\n",
    "    print(\"⚠️ Root agent ('root_agent' or 'weather_agent_team') not found. Cannot define run_team_conversation.\")\n",
    "    # Assign a dummy value to prevent NameError later if the code block runs anyway\n",
    "    root_agent = None # Or set a flag to prevent execution\n",
    "\n",
    "# Only define and run if the root agent exists\n",
    "if root_agent_var_name in globals() and globals()[root_agent_var_name]:\n",
    "    # Define the main async function for the conversation logic.\n",
    "    # The 'await' keywords INSIDE this function are necessary for async operations.\n",
    "    async def run_team_conversation():\n",
    "        print(\"\\n--- Testing Agent Team Delegation ---\")\n",
    "        session_service = InMemorySessionService()\n",
    "        APP_NAME = \"weather_tutorial_agent_team\"\n",
    "        USER_ID = \"user_1_agent_team\"\n",
    "        SESSION_ID = \"session_001_agent_team\"\n",
    "        session = await session_service.create_session(\n",
    "            app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID\n",
    "        )\n",
    "        print(f\"Session created: App='{APP_NAME}', User='{USER_ID}', Session='{SESSION_ID}'\")\n",
    "\n",
    "        actual_root_agent = globals()[root_agent_var_name]\n",
    "        runner_agent_team = Runner( # Or use InMemoryRunner\n",
    "            agent=actual_root_agent,\n",
    "            app_name=APP_NAME,\n",
    "            session_service=session_service\n",
    "        )\n",
    "        print(f\"Runner created for agent '{actual_root_agent.name}'.\")\n",
    "\n",
    "        # --- Interactions using await (correct within async def) ---\n",
    "        await call_agent_async(query = \"Hello there!\",\n",
    "                               runner=runner_agent_team,\n",
    "                               user_id=USER_ID,\n",
    "                               session_id=SESSION_ID)\n",
    "        await call_agent_async(query = \"What is the weather in New York?\",\n",
    "                               runner=runner_agent_team,\n",
    "                               user_id=USER_ID,\n",
    "                               session_id=SESSION_ID)\n",
    "        await call_agent_async(query = \"Thanks, bye!\",\n",
    "                               runner=runner_agent_team,\n",
    "                               user_id=USER_ID,\n",
    "                               session_id=SESSION_ID)\n",
    "\n",
    "    # --- Execute the `run_team_conversation` async function ---\n",
    "    # Choose ONE of the methods below based on your environment.\n",
    "    # Note: This may require API keys for the models used!\n",
    "\n",
    "    # METHOD 1: Direct await (Default for Notebooks/Async REPLs)\n",
    "    # If your environment supports top-level await (like Colab/Jupyter notebooks),\n",
    "    # it means an event loop is already running, so you can directly await the function.\n",
    "    print(\"Attempting execution using 'await' (default for notebooks)...\")\n",
    "    await run_team_conversation()\n",
    "\n",
    "    # METHOD 2: asyncio.run (For Standard Python Scripts [.py])\n",
    "    # If running this code as a standard Python script from your terminal,\n",
    "    # the script context is synchronous. `asyncio.run()` is needed to\n",
    "    # create and manage an event loop to execute your async function.\n",
    "    # To use this method:\n",
    "    # 1. Comment out the `await run_team_conversation()` line above.\n",
    "    # 2. Uncomment the following block:\n",
    "    \"\"\"\n",
    "    import asyncio\n",
    "    if __name__ == \"__main__\": # Ensures this runs only when script is executed directly\n",
    "        print(\"Executing using 'asyncio.run()' (for standard Python scripts)...\")\n",
    "        try:\n",
    "            # This creates an event loop, runs your async function, and closes the loop.\n",
    "            asyncio.run(run_team_conversation())\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "    \"\"\"\n",
    "\n",
    "else:\n",
    "    # This message prints if the root agent variable wasn't found earlier\n",
    "    print(\"\\n⚠️ Skipping agent team conversation execution as the root agent was not successfully defined in a previous step.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3359d9",
   "metadata": {},
   "source": [
    "# Step 4: Adding Memory and Personalization with Session State¶\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef87a56",
   "metadata": {},
   "source": [
    "## Initialize New State Service and State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9724e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ New InMemorySessionService created for state demonstration.\n",
      "✅ Session 'session_state_demo_001' created for user 'user_state_demo'.\n",
      "\n",
      "--- Initial Session State ---\n",
      "{'user_preference_temperature_unit': 'Celsius'}\n"
     ]
    }
   ],
   "source": [
    "# @title 1. Initialize New Session Service and State\n",
    "\n",
    "# Import necessary session components\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "\n",
    "# Create a NEW session service instance for this state demonstration\n",
    "session_service_stateful = InMemorySessionService()\n",
    "print(\"✅ New InMemorySessionService created for state demonstration.\")\n",
    "\n",
    "# Define a NEW session ID for this part of the tutorial\n",
    "SESSION_ID_STATEFUL = \"session_state_demo_001\"\n",
    "USER_ID_STATEFUL = \"user_state_demo\"\n",
    "\n",
    "# Define initial state data - user prefers Celsius initially\n",
    "initial_state = {\n",
    "    \"user_preference_temperature_unit\": \"Celsius\" # Mirip dengan state LangGraph\n",
    "}\n",
    "\n",
    "# Create the session, providing the initial state\n",
    "session_stateful = await session_service_stateful.create_session(\n",
    "    app_name=APP_NAME, # Use the consistent app name\n",
    "    user_id=USER_ID_STATEFUL,\n",
    "    session_id=SESSION_ID_STATEFUL,\n",
    "    state=initial_state # <<< Initialize state during creation\n",
    ")\n",
    "print(f\"✅ Session '{SESSION_ID_STATEFUL}' created for user '{USER_ID_STATEFUL}'.\")\n",
    "\n",
    "# Verify the initial state was set correctly\n",
    "retrieved_session = await session_service_stateful.get_session(app_name=APP_NAME,\n",
    "                                                         user_id=USER_ID_STATEFUL,\n",
    "                                                         session_id = SESSION_ID_STATEFUL)\n",
    "print(\"\\n--- Initial Session State ---\")\n",
    "if retrieved_session:\n",
    "    print(retrieved_session.state)\n",
    "else:\n",
    "    print(\"Error: Could not retrieve session.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b61e77",
   "metadata": {},
   "source": [
    "## Create State-Aware Weather Tool (get_weather_stateful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "201e57af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ State-aware 'get_weather_stateful' tool defined.\n"
     ]
    }
   ],
   "source": [
    "from google.adk.tools.tool_context import ToolContext\n",
    "\n",
    "def get_weather_stateful(city: str, tool_context: ToolContext) -> dict:\n",
    "    \"\"\"Retrieves weather, converts temp unit based on session state.\"\"\"\n",
    "    print(f\"--- Tool: get_weather_stateful called for {city} ---\")\n",
    "\n",
    "    # --- Read preference from state ---\n",
    "    preferred_unit = tool_context.state.get(\"user_preference_temperature_unit\", \"Celsius\") # Default to Celsius\n",
    "    print(f\"--- Tool: Reading state 'user_preference_temperature_unit': {preferred_unit} ---\")\n",
    "\n",
    "    city_normalized = city.lower().replace(\" \", \"\")\n",
    "\n",
    "    # Mock weather data (always stored in Celsius internally)\n",
    "    mock_weather_db = {\n",
    "        \"newyork\": {\"temp_c\": 25, \"condition\": \"sunny\"},\n",
    "        \"london\": {\"temp_c\": 15, \"condition\": \"cloudy\"},\n",
    "        \"tokyo\": {\"temp_c\": 18, \"condition\": \"light rain\"},\n",
    "    }\n",
    "\n",
    "    if city_normalized in mock_weather_db:\n",
    "        data = mock_weather_db[city_normalized]\n",
    "        temp_c = data[\"temp_c\"]\n",
    "        condition = data[\"condition\"]\n",
    "\n",
    "        # Format temperature based on state preference\n",
    "        if preferred_unit == \"Fahrenheit\":\n",
    "            temp_value = (temp_c * 9/5) + 32 # Calculate Fahrenheit\n",
    "            temp_unit = \"°F\"\n",
    "        else: # Default to Celsius\n",
    "            temp_value = temp_c\n",
    "            temp_unit = \"°C\"\n",
    "\n",
    "        report = f\"The weather in {city.capitalize()} is {condition} with a temperature of {temp_value:.0f}{temp_unit}.\"\n",
    "        result = {\"status\": \"success\", \"report\": report}\n",
    "        print(f\"--- Tool: Generated report in {preferred_unit}. Result: {result} ---\")\n",
    "\n",
    "        # Example of writing back to state (optional for this tool)\n",
    "        tool_context.state[\"last_city_checked_stateful\"] = city\n",
    "        print(f\"--- Tool: Updated state 'last_city_checked_stateful': {city} ---\")\n",
    "\n",
    "        return result\n",
    "    else:\n",
    "        # Handle city not found\n",
    "        error_msg = f\"Sorry, I don't have weather information for '{city}'.\"\n",
    "        print(f\"--- Tool: City '{city}' not found. ---\")\n",
    "        return {\"status\": \"error\", \"error_message\": error_msg}\n",
    "\n",
    "print(\"✅ State-aware 'get_weather_stateful' tool defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baeb521c",
   "metadata": {},
   "source": [
    "## Subs-Agent and Root Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e06f585e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Agent 'greeting_agent' redefined.\n",
      "✅ Agent 'farewell_agent' redefined.\n",
      "✅ Root Agent 'weather_agent_v4_stateful' created using stateful tool and output_key.\n",
      "✅ Runner created for stateful root agent 'weather_agent_v4_stateful' using stateful session service.\n"
     ]
    }
   ],
   "source": [
    "# @title 3. Redefine Sub-Agents and Update Root Agent with output_key\n",
    "\n",
    "# Ensure necessary imports: Agent, LiteLlm, Runner\n",
    "from google.adk.agents import Agent\n",
    "from google.adk.models.lite_llm import LiteLlm\n",
    "from google.adk.runners import Runner\n",
    "# Ensure tools 'say_hello', 'say_goodbye' are defined (from Step 3)\n",
    "# Ensure model constants MODEL_GPT_4O, MODEL_GEMINI_2_0_FLASH etc. are defined\n",
    "\n",
    "# --- Redefine Greeting Agent (from Step 3) ---\n",
    "greeting_agent = None\n",
    "try:\n",
    "    greeting_agent = Agent(\n",
    "        model=MODEL_GEMINI_2_5_PRO,\n",
    "        name=\"greeting_agent\",\n",
    "        instruction=\"You are the Greeting Agent. Your ONLY task is to provide a friendly greeting using the 'say_hello' tool. Do nothing else.\",\n",
    "        description=\"Handles simple greetings and hellos using the 'say_hello' tool.\",\n",
    "        tools=[say_hello],\n",
    "    )\n",
    "    print(f\"✅ Agent '{greeting_agent.name}' redefined.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Could not redefine Greeting agent. Error: {e}\")\n",
    "\n",
    "# --- Redefine Farewell Agent (from Step 3) ---\n",
    "farewell_agent = None\n",
    "try:\n",
    "    farewell_agent = Agent(\n",
    "        model=MODEL_GEMINI_2_5_PRO,\n",
    "        name=\"farewell_agent\",\n",
    "        instruction=\"You are the Farewell Agent. Your ONLY task is to provide a polite goodbye message using the 'say_goodbye' tool. Do not perform any other actions.\",\n",
    "        description=\"Handles simple farewells and goodbyes using the 'say_goodbye' tool.\",\n",
    "        tools=[say_goodbye],\n",
    "    )\n",
    "    print(f\"✅ Agent '{farewell_agent.name}' redefined.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Could not redefine Farewell agent. Error: {e}\")\n",
    "\n",
    "# --- Define the Updated Root Agent ---\n",
    "root_agent_stateful = None\n",
    "runner_root_stateful = None # Initialize runner\n",
    "\n",
    "# Check prerequisites before creating the root agent\n",
    "if greeting_agent and farewell_agent and 'get_weather_stateful' in globals():\n",
    "\n",
    "    root_agent_model = MODEL_GEMINI_2_5_PRO # Choose orchestration model\n",
    "\n",
    "    root_agent_stateful = Agent(\n",
    "        name=\"weather_agent_v4_stateful\", # New version name\n",
    "        model=root_agent_model,\n",
    "        description=\"Main agent: Provides weather (state-aware unit), delegates greetings/farewells, saves report to state.\",\n",
    "        instruction=\"You are the main Weather Agent. Your job is to provide weather using 'get_weather_stateful'. \"\n",
    "                    \"The tool will format the temperature based on user preference stored in state. \"\n",
    "                    \"Delegate simple greetings to 'greeting_agent' and farewells to 'farewell_agent'. \"\n",
    "                    \"Handle only weather requests, greetings, and farewells.\",\n",
    "        tools=[get_weather_stateful], # Use the state-aware tool\n",
    "        sub_agents=[greeting_agent, farewell_agent], # Include sub-agents\n",
    "        output_key=\"last_weather_report\" # <<< Auto-save agent's final weather response\n",
    "    )\n",
    "    print(f\"✅ Root Agent '{root_agent_stateful.name}' created using stateful tool and output_key.\")\n",
    "\n",
    "    # --- Create Runner for this Root Agent & NEW Session Service ---\n",
    "    runner_root_stateful = Runner(\n",
    "        agent=root_agent_stateful,\n",
    "        app_name=APP_NAME,\n",
    "        session_service=session_service_stateful # Use the NEW stateful session service\n",
    "    )\n",
    "    print(f\"✅ Runner created for stateful root agent '{runner_root_stateful.agent.name}' using stateful session service.\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ Cannot create stateful root agent. Prerequisites missing.\")\n",
    "    if not greeting_agent: print(\" - greeting_agent definition missing.\")\n",
    "    if not farewell_agent: print(\" - farewell_agent definition missing.\")\n",
    "    if 'get_weather_stateful' not in globals(): print(\" - get_weather_stateful tool missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a05be9",
   "metadata": {},
   "source": [
    "## Interact and State Flow Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f890528c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting execution using 'await' (default for notebooks)...\n",
      "\n",
      "--- Testing State: Temp Unit Conversion & output_key ---\n",
      "--- Turn 1: Requesting weather in London (expect Celsius) ---\n",
      "\n",
      ">>> User Query: What's the weather in London?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:asyncio:Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x71df804ae630>\n",
      "ERROR:asyncio:Unclosed connector\n",
      "connections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x71df73fc6db0>, 9037.961793522)])']\n",
      "connector: <aiohttp.connector.TCPConnector object at 0x71df804d2e70>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Tool: get_weather_stateful called for London ---\n",
      "--- Tool: Reading state 'user_preference_temperature_unit': Celsius ---\n",
      "--- Tool: Generated report in Celsius. Result: {'status': 'success', 'report': 'The weather in London is cloudy with a temperature of 15°C.'} ---\n",
      "--- Tool: Updated state 'last_city_checked_stateful': London ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:asyncio:Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x71df80494170>\n",
      "ERROR:asyncio:Unclosed connector\n",
      "connections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x71df73fc6990>, 9040.624257636)])']\n",
      "connector: <aiohttp.connector.TCPConnector object at 0x71df80496cc0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< Agent Response: The weather in London is cloudy with a temperature of 15°C.\n",
      "\n",
      "\n",
      "--- Manually Updating State: Setting unit to Fahrenheit ---\n",
      "--- Stored session state updated. Current 'user_preference_temperature_unit': Fahrenheit ---\n",
      "\n",
      "--- Turn 2: Requesting weather in New York (expect Fahrenheit) ---\n",
      "\n",
      ">>> User Query: Tell me the weather in New York.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:asyncio:Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x71df804d1e80>\n",
      "ERROR:asyncio:Unclosed connector\n",
      "connections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x71df73f66bd0>, 9043.891747673)])']\n",
      "connector: <aiohttp.connector.TCPConnector object at 0x71df804d2570>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Tool: get_weather_stateful called for New York ---\n",
      "--- Tool: Reading state 'user_preference_temperature_unit': Fahrenheit ---\n",
      "--- Tool: Generated report in Fahrenheit. Result: {'status': 'success', 'report': 'The weather in New york is sunny with a temperature of 77°F.'} ---\n",
      "--- Tool: Updated state 'last_city_checked_stateful': New York ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:asyncio:Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x71df80497050>\n",
      "ERROR:asyncio:Unclosed connector\n",
      "connections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x71df73f66bd0>, 9046.664728436)])']\n",
      "connector: <aiohttp.connector.TCPConnector object at 0x71df80496c00>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< Agent Response: The weather in New york is sunny with a temperature of 77°F.\n",
      "\n",
      "\n",
      "--- Turn 3: Sending a greeting ---\n",
      "\n",
      ">>> User Query: Hi!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:asyncio:Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x71df80496870>\n",
      "ERROR:asyncio:Unclosed connector\n",
      "connections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x71df73fc77d0>, 9054.083782549)])']\n",
      "connector: <aiohttp.connector.TCPConnector object at 0x71df80496a20>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Tool: say_hello called without a specific name (name_arg_value: None) ---\n",
      "<<< Agent Response: Hello there!\n",
      "\n",
      "\n",
      "--- Inspecting Final Session State ---\n",
      "Final Preference: Fahrenheit\n",
      "Final Last Weather Report (from output_key): Hello there!\n",
      "\n",
      "Final Last City Checked (by tool): New York\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:asyncio:Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x71df80496420>\n",
      "ERROR:asyncio:Unclosed connector\n",
      "connections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x71df825a3590>, 9050.864393734)])']\n",
      "connector: <aiohttp.connector.TCPConnector object at 0x71df804971a0>\n",
      "ERROR:asyncio:Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x71df804976b0>\n",
      "ERROR:asyncio:Unclosed connector\n",
      "connections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x71df73fc79b0>, 9056.599425858)])']\n",
      "connector: <aiohttp.connector.TCPConnector object at 0x71df804af110>\n"
     ]
    }
   ],
   "source": [
    "# @title 4. Interact to Test State Flow and output_key\n",
    "import asyncio # Ensure asyncio is imported\n",
    "\n",
    "# Ensure the stateful runner (runner_root_stateful) is available from the previous cell\n",
    "# Ensure call_agent_async, USER_ID_STATEFUL, SESSION_ID_STATEFUL, APP_NAME are defined\n",
    "\n",
    "if 'runner_root_stateful' in globals() and runner_root_stateful:\n",
    "    # Define the main async function for the stateful conversation logic.\n",
    "    # The 'await' keywords INSIDE this function are necessary for async operations.\n",
    "    async def run_stateful_conversation():\n",
    "        print(\"\\n--- Testing State: Temp Unit Conversion & output_key ---\")\n",
    "\n",
    "        # 1. Check weather (Uses initial state: Celsius)\n",
    "        print(\"--- Turn 1: Requesting weather in London (expect Celsius) ---\")\n",
    "        await call_agent_async(query= \"What's the weather in London?\",\n",
    "                               runner=runner_root_stateful,\n",
    "                               user_id=USER_ID_STATEFUL,\n",
    "                               session_id=SESSION_ID_STATEFUL\n",
    "                              )\n",
    "\n",
    "        # 2. Manually update state preference to Fahrenheit - DIRECTLY MODIFY STORAGE\n",
    "        print(\"\\n--- Manually Updating State: Setting unit to Fahrenheit ---\")\n",
    "        try:\n",
    "            # Access the internal storage directly - THIS IS SPECIFIC TO InMemorySessionService for testing\n",
    "            # NOTE: In production with persistent services (Database, VertexAI), you would\n",
    "            # typically update state via agent actions or specific service APIs if available,\n",
    "            # not by direct manipulation of internal storage.\n",
    "            stored_session = session_service_stateful.sessions[APP_NAME][USER_ID_STATEFUL][SESSION_ID_STATEFUL]\n",
    "            stored_session.state[\"user_preference_temperature_unit\"] = \"Fahrenheit\"\n",
    "            # Optional: You might want to update the timestamp as well if any logic depends on it\n",
    "            # import time\n",
    "            # stored_session.last_update_time = time.time()\n",
    "            print(f\"--- Stored session state updated. Current 'user_preference_temperature_unit': {stored_session.state.get('user_preference_temperature_unit', 'Not Set')} ---\") # Added .get for safety\n",
    "        except KeyError:\n",
    "            print(f\"--- Error: Could not retrieve session '{SESSION_ID_STATEFUL}' from internal storage for user '{USER_ID_STATEFUL}' in app '{APP_NAME}' to update state. Check IDs and if session was created. ---\")\n",
    "        except Exception as e:\n",
    "             print(f\"--- Error updating internal session state: {e} ---\")\n",
    "\n",
    "        # 3. Check weather again (Tool should now use Fahrenheit)\n",
    "        # This will also update 'last_weather_report' via output_key\n",
    "        print(\"\\n--- Turn 2: Requesting weather in New York (expect Fahrenheit) ---\")\n",
    "        await call_agent_async(query= \"Tell me the weather in New York.\",\n",
    "                               runner=runner_root_stateful,\n",
    "                               user_id=USER_ID_STATEFUL,\n",
    "                               session_id=SESSION_ID_STATEFUL\n",
    "                              )\n",
    "\n",
    "        # 4. Test basic delegation (should still work)\n",
    "        # This will update 'last_weather_report' again, overwriting the NY weather report\n",
    "        print(\"\\n--- Turn 3: Sending a greeting ---\")\n",
    "        await call_agent_async(query= \"Hi!\",\n",
    "                               runner=runner_root_stateful,\n",
    "                               user_id=USER_ID_STATEFUL,\n",
    "                               session_id=SESSION_ID_STATEFUL\n",
    "                              )\n",
    "\n",
    "    # --- Execute the `run_stateful_conversation` async function ---\n",
    "    # Choose ONE of the methods below based on your environment.\n",
    "\n",
    "    # METHOD 1: Direct await (Default for Notebooks/Async REPLs)\n",
    "    # If your environment supports top-level await (like Colab/Jupyter notebooks),\n",
    "    # it means an event loop is already running, so you can directly await the function.\n",
    "    print(\"Attempting execution using 'await' (default for notebooks)...\")\n",
    "    await run_stateful_conversation()\n",
    "\n",
    "    # METHOD 2: asyncio.run (For Standard Python Scripts [.py])\n",
    "    # If running this code as a standard Python script from your terminal,\n",
    "    # the script context is synchronous. `asyncio.run()` is needed to\n",
    "    # create and manage an event loop to execute your async function.\n",
    "    # To use this method:\n",
    "    # 1. Comment out the `await run_stateful_conversation()` line above.\n",
    "    # 2. Uncomment the following block:\n",
    "    \"\"\"\n",
    "    import asyncio\n",
    "    if __name__ == \"__main__\": # Ensures this runs only when script is executed directly\n",
    "        print(\"Executing using 'asyncio.run()' (for standard Python scripts)...\")\n",
    "        try:\n",
    "            # This creates an event loop, runs your async function, and closes the loop.\n",
    "            asyncio.run(run_stateful_conversation())\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Inspect final session state after the conversation ---\n",
    "    # This block runs after either execution method completes.\n",
    "    print(\"\\n--- Inspecting Final Session State ---\")\n",
    "    final_session = await session_service_stateful.get_session(app_name=APP_NAME,\n",
    "                                                         user_id= USER_ID_STATEFUL,\n",
    "                                                         session_id=SESSION_ID_STATEFUL)\n",
    "    if final_session:\n",
    "        # Use .get() for safer access to potentially missing keys\n",
    "        print(f\"Final Preference: {final_session.state.get('user_preference_temperature_unit', 'Not Set')}\")\n",
    "        print(f\"Final Last Weather Report (from output_key): {final_session.state.get('last_weather_report', 'Not Set')}\")\n",
    "        print(f\"Final Last City Checked (by tool): {final_session.state.get('last_city_checked_stateful', 'Not Set')}\")\n",
    "        # Print full state for detailed view\n",
    "        # print(f\"Full State Dict: {final_session.state}\") # For detailed view\n",
    "    else:\n",
    "        print(\"\\n❌ Error: Could not retrieve final session state.\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n⚠️ Skipping state test conversation. Stateful root agent runner ('runner_root_stateful') is not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7197c97c",
   "metadata": {},
   "source": [
    "# Step 5: Adding Safety - Input Guardrail with before_model_callback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ca718b",
   "metadata": {},
   "source": [
    "## Guardrail Callback Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6d138cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ block_keyword_guardrail function defined.\n"
     ]
    }
   ],
   "source": [
    "# @title 1. Define the before_model_callback Guardrail\n",
    "\n",
    "# Ensure necessary imports are available\n",
    "from google.adk.agents.callback_context import CallbackContext\n",
    "from google.adk.models.llm_request import LlmRequest\n",
    "from google.adk.models.llm_response import LlmResponse\n",
    "from google.genai import types # For creating response content\n",
    "from typing import Optional\n",
    "\n",
    "def block_keyword_guardrail(\n",
    "    callback_context: CallbackContext, llm_request: LlmRequest\n",
    ") -> Optional[LlmResponse]:\n",
    "    \"\"\"\n",
    "    Inspects the latest user message for 'BLOCK'. If found, blocks the LLM call\n",
    "    and returns a predefined LlmResponse. Otherwise, returns None to proceed.\n",
    "    \"\"\"\n",
    "    agent_name = callback_context.agent_name # Get the name of the agent whose model call is being intercepted\n",
    "    print(f\"--- Callback: block_keyword_guardrail running for agent: {agent_name} ---\")\n",
    "\n",
    "    # Extract the text from the latest user message in the request history\n",
    "    last_user_message_text = \"\"\n",
    "    if llm_request.contents:\n",
    "        # Find the most recent message with role 'user'\n",
    "        for content in reversed(llm_request.contents):\n",
    "            if content.role == 'user' and content.parts:\n",
    "                # Assuming text is in the first part for simplicity\n",
    "                if content.parts[0].text:\n",
    "                    last_user_message_text = content.parts[0].text\n",
    "                    break # Found the last user message text\n",
    "\n",
    "    print(f\"--- Callback: Inspecting last user message: '{last_user_message_text[:100]}...' ---\") # Log first 100 chars\n",
    "\n",
    "    # --- Guardrail Logic ---\n",
    "    keyword_to_block = \"BLOCK\"\n",
    "    if keyword_to_block in last_user_message_text.upper(): # Case-insensitive check\n",
    "        print(f\"--- Callback: Found '{keyword_to_block}'. Blocking LLM call! ---\")\n",
    "        # Optionally, set a flag in state to record the block event\n",
    "        callback_context.state[\"guardrail_block_keyword_triggered\"] = True\n",
    "        print(f\"--- Callback: Set state 'guardrail_block_keyword_triggered': True ---\")\n",
    "\n",
    "        # Construct and return an LlmResponse to stop the flow and send this back instead\n",
    "        return LlmResponse(\n",
    "            content=types.Content(\n",
    "                role=\"model\", # Mimic a response from the agent's perspective\n",
    "                parts=[types.Part(text=f\"I cannot process this request because it contains the blocked keyword '{keyword_to_block}'.\")],\n",
    "            )\n",
    "            # Note: You could also set an error_message field here if needed\n",
    "        )\n",
    "    else:\n",
    "        # Keyword not found, allow the request to proceed to the LLM\n",
    "        print(f\"--- Callback: Keyword not found. Allowing LLM call for {agent_name}. ---\")\n",
    "        return None # Returning None signals ADK to continue normally\n",
    "\n",
    "print(\"✅ block_keyword_guardrail function defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182362e5",
   "metadata": {},
   "source": [
    "## Root Agent Use Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3ae2f5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Sub-Agent 'greeting_agent' redefined.\n",
      "✅ Sub-Agent 'farewell_agent' redefined.\n",
      "✅ Root Agent 'weather_agent_v5_model_guardrail' created with before_model_callback.\n",
      "✅ Runner created for guardrail agent 'weather_agent_v5_model_guardrail', using stateful session service.\n"
     ]
    }
   ],
   "source": [
    "# @title 2. Update Root Agent with before_model_callback\n",
    "\n",
    "\n",
    "# --- Redefine Sub-Agents (Ensures they exist in this context) ---\n",
    "greeting_agent = None\n",
    "try:\n",
    "    # Use a defined model constant\n",
    "    greeting_agent = Agent(\n",
    "        model=MODEL_GEMINI_2_5_PRO,\n",
    "        name=\"greeting_agent\", # Keep original name for consistency\n",
    "        instruction=\"You are the Greeting Agent. Your ONLY task is to provide a friendly greeting using the 'say_hello' tool. Do nothing else.\",\n",
    "        description=\"Handles simple greetings and hellos using the 'say_hello' tool.\",\n",
    "        tools=[say_hello],\n",
    "    )\n",
    "    print(f\"✅ Sub-Agent '{greeting_agent.name}' redefined.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Could not redefine Greeting agent. Check Model/API Key ({greeting_agent.model}). Error: {e}\")\n",
    "\n",
    "farewell_agent = None\n",
    "try:\n",
    "    # Use a defined model constant\n",
    "    farewell_agent = Agent(\n",
    "        model=MODEL_GEMINI_2_5_PRO,\n",
    "        name=\"farewell_agent\", # Keep original name\n",
    "        instruction=\"You are the Farewell Agent. Your ONLY task is to provide a polite goodbye message using the 'say_goodbye' tool. Do not perform any other actions.\",\n",
    "        description=\"Handles simple farewells and goodbyes using the 'say_goodbye' tool.\",\n",
    "        tools=[say_goodbye],\n",
    "    )\n",
    "    print(f\"✅ Sub-Agent '{farewell_agent.name}' redefined.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Could not redefine Farewell agent. Check Model/API Key ({farewell_agent.model}). Error: {e}\")\n",
    "\n",
    "\n",
    "# --- Define the Root Agent with the Callback ---\n",
    "root_agent_model_guardrail = None\n",
    "runner_root_model_guardrail = None\n",
    "\n",
    "# Check all components before proceeding\n",
    "if greeting_agent and farewell_agent and 'get_weather_stateful' in globals() and 'block_keyword_guardrail' in globals():\n",
    "\n",
    "    # Use a defined model constant\n",
    "    root_agent_model = MODEL_GEMINI_2_5_PRO\n",
    "\n",
    "    root_agent_model_guardrail = Agent(\n",
    "        name=\"weather_agent_v5_model_guardrail\", # New version name for clarity\n",
    "        model=root_agent_model,\n",
    "        description=\"Main agent: Handles weather, delegates greetings/farewells, includes input keyword guardrail.\",\n",
    "        instruction=\"You are the main Weather Agent. Provide weather using 'get_weather_stateful'. \"\n",
    "                    \"Delegate simple greetings to 'greeting_agent' and farewells to 'farewell_agent'. \"\n",
    "                    \"Handle only weather requests, greetings, and farewells.\",\n",
    "        tools=[get_weather_stateful],\n",
    "        sub_agents=[greeting_agent, farewell_agent], # Reference the redefined sub-agents\n",
    "        output_key=\"last_weather_report\", # Keep output_key from Step 4\n",
    "        before_model_callback=block_keyword_guardrail # <<< Assign the guardrail callback\n",
    "    )\n",
    "    print(f\"✅ Root Agent '{root_agent_model_guardrail.name}' created with before_model_callback.\")\n",
    "\n",
    "    # --- Create Runner for this Agent, Using SAME Stateful Session Service ---\n",
    "    # Ensure session_service_stateful exists from Step 4\n",
    "    if 'session_service_stateful' in globals():\n",
    "        runner_root_model_guardrail = Runner(\n",
    "            agent=root_agent_model_guardrail,\n",
    "            app_name=APP_NAME, # Use consistent APP_NAME\n",
    "            session_service=session_service_stateful # <<< Use the service from Step 4\n",
    "        )\n",
    "        print(f\"✅ Runner created for guardrail agent '{runner_root_model_guardrail.agent.name}', using stateful session service.\")\n",
    "    else:\n",
    "        print(\"❌ Cannot create runner. 'session_service_stateful' from Step 4 is missing.\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ Cannot create root agent with model guardrail. One or more prerequisites are missing or failed initialization:\")\n",
    "    if not greeting_agent: print(\"   - Greeting Agent\")\n",
    "    if not farewell_agent: print(\"   - Farewell Agent\")\n",
    "    if 'get_weather_stateful' not in globals(): print(\"   - 'get_weather_stateful' tool\")\n",
    "    if 'block_keyword_guardrail' not in globals(): print(\"   - 'block_keyword_guardrail' callback\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4635d74c",
   "metadata": {},
   "source": [
    "## Interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a06dd308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting execution using 'await' (default for notebooks)...\n",
      "\n",
      "--- Testing Model Input Guardrail ---\n",
      "--- Turn 1: Requesting weather in London (expect allowed, Fahrenheit) ---\n",
      "\n",
      ">>> User Query: What is the weather in London?\n",
      "--- Callback: block_keyword_guardrail running for agent: weather_agent_v5_model_guardrail ---\n",
      "--- Callback: Inspecting last user message: 'For context:...' ---\n",
      "--- Callback: Keyword not found. Allowing LLM call for weather_agent_v5_model_guardrail. ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:asyncio:Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x71df80484110>\n",
      "ERROR:asyncio:Unclosed connector\n",
      "connections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x71df73e608f0>, 10235.65435576)])']\n",
      "connector: <aiohttp.connector.TCPConnector object at 0x71df804859a0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Tool: get_weather_stateful called for London ---\n",
      "--- Tool: Reading state 'user_preference_temperature_unit': Fahrenheit ---\n",
      "--- Tool: Generated report in Fahrenheit. Result: {'status': 'success', 'report': 'The weather in London is cloudy with a temperature of 59°F.'} ---\n",
      "--- Tool: Updated state 'last_city_checked_stateful': London ---\n",
      "--- Callback: block_keyword_guardrail running for agent: weather_agent_v5_model_guardrail ---\n",
      "--- Callback: Inspecting last user message: 'For context:...' ---\n",
      "--- Callback: Keyword not found. Allowing LLM call for weather_agent_v5_model_guardrail. ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:asyncio:Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x71df80487b90>\n",
      "ERROR:asyncio:Unclosed connector\n",
      "connections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x71df73e603b0>, 10232.055487399)])']\n",
      "connector: <aiohttp.connector.TCPConnector object at 0x71df80487800>\n",
      "ERROR:asyncio:Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x71df804d7e60>\n",
      "ERROR:asyncio:Unclosed connector\n",
      "connections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x71df73e60b30>, 10238.018042858)])']\n",
      "connector: <aiohttp.connector.TCPConnector object at 0x71df804d6870>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< Agent Response: The weather in London is cloudy with a temperature of 59°F.\n",
      "\n",
      "\n",
      "--- Turn 2: Requesting with blocked keyword (expect blocked) ---\n",
      "\n",
      ">>> User Query: BLOCK the request for weather in Tokyo\n",
      "--- Callback: block_keyword_guardrail running for agent: weather_agent_v5_model_guardrail ---\n",
      "--- Callback: Inspecting last user message: 'BLOCK the request for weather in Tokyo...' ---\n",
      "--- Callback: Found 'BLOCK'. Blocking LLM call! ---\n",
      "--- Callback: Set state 'guardrail_block_keyword_triggered': True ---\n",
      "<<< Agent Response: I cannot process this request because it contains the blocked keyword 'BLOCK'.\n",
      "\n",
      "--- Turn 3: Sending a greeting (expect allowed) ---\n",
      "\n",
      ">>> User Query: Hello again\n",
      "--- Callback: block_keyword_guardrail running for agent: weather_agent_v5_model_guardrail ---\n",
      "--- Callback: Inspecting last user message: 'Hello again...' ---\n",
      "--- Callback: Keyword not found. Allowing LLM call for weather_agent_v5_model_guardrail. ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:asyncio:Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x71df804877d0>\n",
      "ERROR:asyncio:Unclosed connector\n",
      "connections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x71df73e605f0>, 10246.700076494)])']\n",
      "connector: <aiohttp.connector.TCPConnector object at 0x71df80486720>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Tool: say_hello called without a specific name (name_arg_value: None) ---\n",
      "<<< Agent Response: Hello there!\n",
      "\n",
      "\n",
      "--- Inspecting Final Session State (After Guardrail Test) ---\n",
      "Guardrail Triggered Flag: True\n",
      "Last Weather Report: Hello there!\n",
      "\n",
      "Temperature Unit: Fahrenheit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:asyncio:Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x71df80e60650>\n",
      "ERROR:asyncio:Unclosed connector\n",
      "connections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x71df73e1bfb0>, 10241.858255989)])']\n",
      "connector: <aiohttp.connector.TCPConnector object at 0x71df80e610a0>\n",
      "ERROR:asyncio:Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x71df804842c0>\n",
      "ERROR:asyncio:Unclosed connector\n",
      "connections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x71df73e608f0>, 10249.34249983)])']\n",
      "connector: <aiohttp.connector.TCPConnector object at 0x71df80485be0>\n"
     ]
    }
   ],
   "source": [
    "# @title 3. Interact to Test the Model Input Guardrail\n",
    "import asyncio # Ensure asyncio is imported\n",
    "\n",
    "# Ensure the runner for the guardrail agent is available\n",
    "if 'runner_root_model_guardrail' in globals() and runner_root_model_guardrail:\n",
    "    # Define the main async function for the guardrail test conversation.\n",
    "    # The 'await' keywords INSIDE this function are necessary for async operations.\n",
    "    async def run_guardrail_test_conversation():\n",
    "        print(\"\\n--- Testing Model Input Guardrail ---\")\n",
    "\n",
    "        # Use the runner for the agent with the callback and the existing stateful session ID\n",
    "        # Define a helper lambda for cleaner interaction calls\n",
    "        interaction_func = lambda query: call_agent_async(query,\n",
    "                                                         runner_root_model_guardrail,\n",
    "                                                         USER_ID_STATEFUL, # Use existing user ID\n",
    "                                                         SESSION_ID_STATEFUL # Use existing session ID\n",
    "                                                        )\n",
    "        # 1. Normal request (Callback allows, should use Fahrenheit from previous state change)\n",
    "        print(\"--- Turn 1: Requesting weather in London (expect allowed, Fahrenheit) ---\")\n",
    "        await interaction_func(\"What is the weather in London?\")\n",
    "\n",
    "        # 2. Request containing the blocked keyword (Callback intercepts)\n",
    "        print(\"\\n--- Turn 2: Requesting with blocked keyword (expect blocked) ---\")\n",
    "        await interaction_func(\"BLOCK the request for weather in Tokyo\") # Callback should catch \"BLOCK\"\n",
    "\n",
    "        # 3. Normal greeting (Callback allows root agent, delegation happens)\n",
    "        print(\"\\n--- Turn 3: Sending a greeting (expect allowed) ---\")\n",
    "        await interaction_func(\"Hello again\")\n",
    "\n",
    "    # --- Execute the `run_guardrail_test_conversation` async function ---\n",
    "    # Choose ONE of the methods below based on your environment.\n",
    "\n",
    "    # METHOD 1: Direct await (Default for Notebooks/Async REPLs)\n",
    "    # If your environment supports top-level await (like Colab/Jupyter notebooks),\n",
    "    # it means an event loop is already running, so you can directly await the function.\n",
    "    print(\"Attempting execution using 'await' (default for notebooks)...\")\n",
    "    await run_guardrail_test_conversation()\n",
    "\n",
    "    # METHOD 2: asyncio.run (For Standard Python Scripts [.py])\n",
    "    # If running this code as a standard Python script from your terminal,\n",
    "    # the script context is synchronous. `asyncio.run()` is needed to\n",
    "    # create and manage an event loop to execute your async function.\n",
    "    # To use this method:\n",
    "    # 1. Comment out the `await run_guardrail_test_conversation()` line above.\n",
    "    # 2. Uncomment the following block:\n",
    "    \"\"\"\n",
    "    import asyncio\n",
    "    if __name__ == \"__main__\": # Ensures this runs only when script is executed directly\n",
    "        print(\"Executing using 'asyncio.run()' (for standard Python scripts)...\")\n",
    "        try:\n",
    "            # This creates an event loop, runs your async function, and closes the loop.\n",
    "            asyncio.run(run_guardrail_test_conversation())\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Inspect final session state after the conversation ---\n",
    "    # This block runs after either execution method completes.\n",
    "    # Optional: Check state for the trigger flag set by the callback\n",
    "    print(\"\\n--- Inspecting Final Session State (After Guardrail Test) ---\")\n",
    "    # Use the session service instance associated with this stateful session\n",
    "    final_session = await session_service_stateful.get_session(app_name=APP_NAME,\n",
    "                                                         user_id=USER_ID_STATEFUL,\n",
    "                                                         session_id=SESSION_ID_STATEFUL)\n",
    "    if final_session:\n",
    "        # Use .get() for safer access\n",
    "        print(f\"Guardrail Triggered Flag: {final_session.state.get('guardrail_block_keyword_triggered', 'Not Set (or False)')}\")\n",
    "        print(f\"Last Weather Report: {final_session.state.get('last_weather_report', 'Not Set')}\") # Should be London weather if successful\n",
    "        print(f\"Temperature Unit: {final_session.state.get('user_preference_temperature_unit', 'Not Set')}\") # Should be Fahrenheit\n",
    "        # print(f\"Full State Dict: {final_session.state}\") # For detailed view\n",
    "    else:\n",
    "        print(\"\\n❌ Error: Could not retrieve final session state.\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n⚠️ Skipping model guardrail test. Runner ('runner_root_model_guardrail') is not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4ab4e1",
   "metadata": {},
   "source": [
    "# Step 6: Adding Safety - Tool Argument Guardrail (before_tool_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8224a030",
   "metadata": {},
   "source": [
    "## Tool Guardrail Callback Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6e650355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ block_paris_tool_guardrail function defined.\n"
     ]
    }
   ],
   "source": [
    "# @title 1. Define the before_tool_callback Guardrail\n",
    "\n",
    "# Ensure necessary imports are available\n",
    "from google.adk.tools.base_tool import BaseTool\n",
    "from google.adk.tools.tool_context import ToolContext\n",
    "from typing import Optional, Dict, Any # For type hints\n",
    "\n",
    "def block_paris_tool_guardrail(\n",
    "    tool: BaseTool, args: Dict[str, Any], tool_context: ToolContext\n",
    ") -> Optional[Dict]:\n",
    "    \"\"\"\n",
    "    Checks if 'get_weather_stateful' is called for 'Paris'.\n",
    "    If so, blocks the tool execution and returns a specific error dictionary.\n",
    "    Otherwise, allows the tool call to proceed by returning None.\n",
    "    \"\"\"\n",
    "    tool_name = tool.name\n",
    "    agent_name = tool_context.agent_name # Agent attempting the tool call\n",
    "    print(f\"--- Callback: block_paris_tool_guardrail running for tool '{tool_name}' in agent '{agent_name}' ---\")\n",
    "    print(f\"--- Callback: Inspecting args: {args} ---\")\n",
    "\n",
    "    # --- Guardrail Logic ---\n",
    "    target_tool_name = \"get_weather_stateful\" # Match the function name used by FunctionTool\n",
    "    blocked_city = \"paris\"\n",
    "\n",
    "    # Check if it's the correct tool and the city argument matches the blocked city\n",
    "    if tool_name == target_tool_name:\n",
    "        city_argument = args.get(\"city\", \"\") # Safely get the 'city' argument\n",
    "        if city_argument and city_argument.lower() == blocked_city:\n",
    "            print(f\"--- Callback: Detected blocked city '{city_argument}'. Blocking tool execution! ---\")\n",
    "            # Optionally update state\n",
    "            tool_context.state[\"guardrail_tool_block_triggered\"] = True\n",
    "            print(f\"--- Callback: Set state 'guardrail_tool_block_triggered': True ---\")\n",
    "\n",
    "            # Return a dictionary matching the tool's expected output format for errors\n",
    "            # This dictionary becomes the tool's result, skipping the actual tool run.\n",
    "            return {\n",
    "                \"status\": \"error\",\n",
    "                \"error_message\": f\"Policy restriction: Weather checks for '{city_argument.capitalize()}' are currently disabled by a tool guardrail.\"\n",
    "            }\n",
    "        else:\n",
    "             print(f\"--- Callback: City '{city_argument}' is allowed for tool '{tool_name}'. ---\")\n",
    "    else:\n",
    "        print(f\"--- Callback: Tool '{tool_name}' is not the target tool. Allowing. ---\")\n",
    "\n",
    "\n",
    "    # If the checks above didn't return a dictionary, allow the tool to execute\n",
    "    print(f\"--- Callback: Allowing tool '{tool_name}' to proceed. ---\")\n",
    "    return None # Returning None allows the actual tool function to run\n",
    "\n",
    "print(\"✅ block_paris_tool_guardrail function defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b43dda",
   "metadata": {},
   "source": [
    "## Root Agen with Tool Callback and Model Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4ccd6882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Sub-Agent 'greeting_agent' redefined.\n",
      "✅ Sub-Agent 'farewell_agent' redefined.\n",
      "✅ Root Agent 'weather_agent_v6_tool_guardrail' created with BOTH callbacks.\n",
      "✅ Runner created for tool guardrail agent 'weather_agent_v6_tool_guardrail', using stateful session service.\n"
     ]
    }
   ],
   "source": [
    "# @title 2. Update Root Agent with BOTH Callbacks (Self-Contained)\n",
    "\n",
    "# --- Ensure Prerequisites are Defined ---\n",
    "# (Include or ensure execution of definitions for: Agent, LiteLlm, Runner, ToolContext,\n",
    "#  MODEL constants, say_hello, say_goodbye, greeting_agent, farewell_agent,\n",
    "#  get_weather_stateful, block_keyword_guardrail, block_paris_tool_guardrail)\n",
    "\n",
    "# --- Redefine Sub-Agents (Ensures they exist in this context) ---\n",
    "greeting_agent = None\n",
    "try:\n",
    "    # Use a defined model constant\n",
    "    greeting_agent = Agent(\n",
    "        model=MODEL_GEMINI_2_5_PRO,\n",
    "        name=\"greeting_agent\", # Keep original name for consistency\n",
    "        instruction=\"You are the Greeting Agent. Your ONLY task is to provide a friendly greeting using the 'say_hello' tool. Do nothing else.\",\n",
    "        description=\"Handles simple greetings and hellos using the 'say_hello' tool.\",\n",
    "        tools=[say_hello],\n",
    "    )\n",
    "    print(f\"✅ Sub-Agent '{greeting_agent.name}' redefined.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Could not redefine Greeting agent. Check Model/API Key ({greeting_agent.model}). Error: {e}\")\n",
    "\n",
    "farewell_agent = None\n",
    "try:\n",
    "    # Use a defined model constant\n",
    "    farewell_agent = Agent(\n",
    "        model=MODEL_GEMINI_2_5_PRO,\n",
    "        name=\"farewell_agent\", # Keep original name\n",
    "        instruction=\"You are the Farewell Agent. Your ONLY task is to provide a polite goodbye message using the 'say_goodbye' tool. Do not perform any other actions.\",\n",
    "        description=\"Handles simple farewells and goodbyes using the 'say_goodbye' tool.\",\n",
    "        tools=[say_goodbye],\n",
    "    )\n",
    "    print(f\"✅ Sub-Agent '{farewell_agent.name}' redefined.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Could not redefine Farewell agent. Check Model/API Key ({farewell_agent.model}). Error: {e}\")\n",
    "\n",
    "# --- Define the Root Agent with Both Callbacks ---\n",
    "root_agent_tool_guardrail = None\n",
    "runner_root_tool_guardrail = None\n",
    "\n",
    "if ('greeting_agent' in globals() and greeting_agent and\n",
    "    'farewell_agent' in globals() and farewell_agent and\n",
    "    'get_weather_stateful' in globals() and\n",
    "    'block_keyword_guardrail' in globals() and\n",
    "    'block_paris_tool_guardrail' in globals()):\n",
    "\n",
    "    root_agent_model = MODEL_GEMINI_2_5_PRO\n",
    "\n",
    "    root_agent_tool_guardrail = Agent(\n",
    "        name=\"weather_agent_v6_tool_guardrail\", # New version name\n",
    "        model=root_agent_model,\n",
    "        description=\"Main agent: Handles weather, delegates, includes input AND tool guardrails.\",\n",
    "        instruction=\"You are the main Weather Agent. Provide weather using 'get_weather_stateful'. \"\n",
    "                    \"Delegate greetings to 'greeting_agent' and farewells to 'farewell_agent'. \"\n",
    "                    \"Handle only weather, greetings, and farewells.\",\n",
    "        tools=[get_weather_stateful],\n",
    "        sub_agents=[greeting_agent, farewell_agent],\n",
    "        output_key=\"last_weather_report\",\n",
    "        before_model_callback=block_keyword_guardrail, # Keep model guardrail\n",
    "        before_tool_callback=block_paris_tool_guardrail # <<< Add tool guardrail\n",
    "    )\n",
    "    print(f\"✅ Root Agent '{root_agent_tool_guardrail.name}' created with BOTH callbacks.\")\n",
    "\n",
    "    # --- Create Runner, Using SAME Stateful Session Service ---\n",
    "    if 'session_service_stateful' in globals():\n",
    "        runner_root_tool_guardrail = Runner(\n",
    "            agent=root_agent_tool_guardrail,\n",
    "            app_name=APP_NAME,\n",
    "            session_service=session_service_stateful # <<< Use the service from Step 4/5\n",
    "        )\n",
    "        print(f\"✅ Runner created for tool guardrail agent '{runner_root_tool_guardrail.agent.name}', using stateful session service.\")\n",
    "    else:\n",
    "        print(\"❌ Cannot create runner. 'session_service_stateful' from Step 4/5 is missing.\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ Cannot create root agent with tool guardrail. Prerequisites missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23ce1d6",
   "metadata": {},
   "source": [
    "## Interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "655e369a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting execution using 'await' (default for notebooks)...\n",
      "\n",
      "--- Testing Tool Argument Guardrail ('Paris' blocked) ---\n",
      "--- Turn 1: Requesting weather in New York (expect allowed) ---\n",
      "\n",
      ">>> User Query: What's the weather in New York?\n",
      "--- Callback: block_keyword_guardrail running for agent: weather_agent_v6_tool_guardrail ---\n",
      "--- Callback: Inspecting last user message: 'For context:...' ---\n",
      "--- Callback: Keyword not found. Allowing LLM call for weather_agent_v6_tool_guardrail. ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:asyncio:Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x71df80520d40>\n",
      "ERROR:asyncio:Unclosed connector\n",
      "connections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x71df73d03bf0>, 10805.825713574)])']\n",
      "connector: <aiohttp.connector.TCPConnector object at 0x71df80520c80>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Callback: block_paris_tool_guardrail running for tool 'get_weather_stateful' in agent 'weather_agent_v6_tool_guardrail' ---\n",
      "--- Callback: Inspecting args: {'city': 'New York'} ---\n",
      "--- Callback: City 'New York' is allowed for tool 'get_weather_stateful'. ---\n",
      "--- Callback: Allowing tool 'get_weather_stateful' to proceed. ---\n",
      "--- Tool: get_weather_stateful called for New York ---\n",
      "--- Tool: Reading state 'user_preference_temperature_unit': Fahrenheit ---\n",
      "--- Tool: Generated report in Fahrenheit. Result: {'status': 'success', 'report': 'The weather in New york is sunny with a temperature of 77°F.'} ---\n",
      "--- Tool: Updated state 'last_city_checked_stateful': New York ---\n",
      "--- Callback: block_keyword_guardrail running for agent: weather_agent_v6_tool_guardrail ---\n",
      "--- Callback: Inspecting last user message: 'For context:...' ---\n",
      "--- Callback: Keyword not found. Allowing LLM call for weather_agent_v6_tool_guardrail. ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:asyncio:Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x71df8051bd10>\n",
      "ERROR:asyncio:Unclosed connector\n",
      "connections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x71df73d036b0>, 10802.996496454)])']\n",
      "connector: <aiohttp.connector.TCPConnector object at 0x71df804d7d10>\n",
      "ERROR:asyncio:Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x71df80522f60>\n",
      "ERROR:asyncio:Unclosed connector\n",
      "connections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x71df73d03e30>, 10809.708151353)])']\n",
      "connector: <aiohttp.connector.TCPConnector object at 0x71df80522720>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< Agent Response: The weather in New york is sunny with a temperature of 77°F.\n",
      "\n",
      "\n",
      "--- Turn 2: Requesting weather in Paris (expect blocked by tool guardrail) ---\n",
      "\n",
      ">>> User Query: How about Paris?\n",
      "--- Callback: block_keyword_guardrail running for agent: weather_agent_v6_tool_guardrail ---\n",
      "--- Callback: Inspecting last user message: 'How about Paris?...' ---\n",
      "--- Callback: Keyword not found. Allowing LLM call for weather_agent_v6_tool_guardrail. ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:asyncio:Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x71df80523920>\n",
      "ERROR:asyncio:Unclosed connector\n",
      "connections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x71df73d03e30>, 10813.308593349)])']\n",
      "connector: <aiohttp.connector.TCPConnector object at 0x71df80523d40>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Callback: block_paris_tool_guardrail running for tool 'get_weather_stateful' in agent 'weather_agent_v6_tool_guardrail' ---\n",
      "--- Callback: Inspecting args: {'city': 'Paris'} ---\n",
      "--- Callback: Detected blocked city 'Paris'. Blocking tool execution! ---\n",
      "--- Callback: Set state 'guardrail_tool_block_triggered': True ---\n",
      "--- Callback: block_keyword_guardrail running for agent: weather_agent_v6_tool_guardrail ---\n",
      "--- Callback: Inspecting last user message: 'How about Paris?...' ---\n",
      "--- Callback: Keyword not found. Allowing LLM call for weather_agent_v6_tool_guardrail. ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:asyncio:Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x71df80522f90>\n",
      "ERROR:asyncio:Unclosed connector\n",
      "connections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x71df73e63950>, 10815.7506796)])']\n",
      "connector: <aiohttp.connector.TCPConnector object at 0x71df80523470>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< Agent Response: I am sorry, but I cannot fulfill this request. The city you provided is currently restricted.\n",
      "\n",
      "--- Turn 3: Requesting weather in London (expect allowed) ---\n",
      "\n",
      ">>> User Query: Tell me the weather in London.\n",
      "--- Callback: block_keyword_guardrail running for agent: weather_agent_v6_tool_guardrail ---\n",
      "--- Callback: Inspecting last user message: 'Tell me the weather in London....' ---\n",
      "--- Callback: Keyword not found. Allowing LLM call for weather_agent_v6_tool_guardrail. ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:asyncio:Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x71df8051ad50>\n",
      "ERROR:asyncio:Unclosed connector\n",
      "connections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x71df73e63950>, 10820.052421149)])']\n",
      "connector: <aiohttp.connector.TCPConnector object at 0x71df8051aff0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Callback: block_paris_tool_guardrail running for tool 'get_weather_stateful' in agent 'weather_agent_v6_tool_guardrail' ---\n",
      "--- Callback: Inspecting args: {'city': 'London'} ---\n",
      "--- Callback: City 'London' is allowed for tool 'get_weather_stateful'. ---\n",
      "--- Callback: Allowing tool 'get_weather_stateful' to proceed. ---\n",
      "--- Tool: get_weather_stateful called for London ---\n",
      "--- Tool: Reading state 'user_preference_temperature_unit': Fahrenheit ---\n",
      "--- Tool: Generated report in Fahrenheit. Result: {'status': 'success', 'report': 'The weather in London is cloudy with a temperature of 59°F.'} ---\n",
      "--- Tool: Updated state 'last_city_checked_stateful': London ---\n",
      "--- Callback: block_keyword_guardrail running for agent: weather_agent_v6_tool_guardrail ---\n",
      "--- Callback: Inspecting last user message: 'Tell me the weather in London....' ---\n",
      "--- Callback: Keyword not found. Allowing LLM call for weather_agent_v6_tool_guardrail. ---\n",
      "<<< Agent Response: The weather in London is cloudy with a temperature of 59°F.\n",
      "\n",
      "--- Inspecting Final Session State (After Tool Guardrail Test) ---\n",
      "Tool Guardrail Triggered Flag: True\n",
      "Last Weather Report: The weather in London is cloudy with a temperature of 59°F.\n",
      "Temperature Unit: Fahrenheit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:asyncio:Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x71df8051a960>\n",
      "ERROR:asyncio:Unclosed connector\n",
      "connections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x71df73e62f90>, 10822.699079258)])']\n",
      "connector: <aiohttp.connector.TCPConnector object at 0x71df8051a9c0>\n"
     ]
    }
   ],
   "source": [
    "# @title 3. Interact to Test the Tool Argument Guardrail\n",
    "import asyncio # Ensure asyncio is imported\n",
    "\n",
    "# Ensure the runner for the tool guardrail agent is available\n",
    "if 'runner_root_tool_guardrail' in globals() and runner_root_tool_guardrail:\n",
    "    # Define the main async function for the tool guardrail test conversation.\n",
    "    # The 'await' keywords INSIDE this function are necessary for async operations.\n",
    "    async def run_tool_guardrail_test():\n",
    "        print(\"\\n--- Testing Tool Argument Guardrail ('Paris' blocked) ---\")\n",
    "\n",
    "        # Use the runner for the agent with both callbacks and the existing stateful session\n",
    "        # Define a helper lambda for cleaner interaction calls\n",
    "        interaction_func = lambda query: call_agent_async(query,\n",
    "                                                         runner_root_tool_guardrail,\n",
    "                                                         USER_ID_STATEFUL, # Use existing user ID\n",
    "                                                         SESSION_ID_STATEFUL # Use existing session ID\n",
    "                                                        )\n",
    "        # 1. Allowed city (Should pass both callbacks, use Fahrenheit state)\n",
    "        print(\"--- Turn 1: Requesting weather in New York (expect allowed) ---\")\n",
    "        await interaction_func(\"What's the weather in New York?\")\n",
    "\n",
    "        # 2. Blocked city (Should pass model callback, but be blocked by tool callback)\n",
    "        print(\"\\n--- Turn 2: Requesting weather in Paris (expect blocked by tool guardrail) ---\")\n",
    "        await interaction_func(\"How about Paris?\") # Tool callback should intercept this\n",
    "\n",
    "        # 3. Another allowed city (Should work normally again)\n",
    "        print(\"\\n--- Turn 3: Requesting weather in London (expect allowed) ---\")\n",
    "        await interaction_func(\"Tell me the weather in London.\")\n",
    "\n",
    "    # --- Execute the `run_tool_guardrail_test` async function ---\n",
    "    # Choose ONE of the methods below based on your environment.\n",
    "\n",
    "    # METHOD 1: Direct await (Default for Notebooks/Async REPLs)\n",
    "    # If your environment supports top-level await (like Colab/Jupyter notebooks),\n",
    "    # it means an event loop is already running, so you can directly await the function.\n",
    "    print(\"Attempting execution using 'await' (default for notebooks)...\")\n",
    "    await run_tool_guardrail_test()\n",
    "\n",
    "    # METHOD 2: asyncio.run (For Standard Python Scripts [.py])\n",
    "    # If running this code as a standard Python script from your terminal,\n",
    "    # the script context is synchronous. `asyncio.run()` is needed to\n",
    "    # create and manage an event loop to execute your async function.\n",
    "    # To use this method:\n",
    "    # 1. Comment out the `await run_tool_guardrail_test()` line above.\n",
    "    # 2. Uncomment the following block:\n",
    "    \"\"\"\n",
    "    import asyncio\n",
    "    if __name__ == \"__main__\": # Ensures this runs only when script is executed directly\n",
    "        print(\"Executing using 'asyncio.run()' (for standard Python scripts)...\")\n",
    "        try:\n",
    "            # This creates an event loop, runs your async function, and closes the loop.\n",
    "            asyncio.run(run_tool_guardrail_test())\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Inspect final session state after the conversation ---\n",
    "    # This block runs after either execution method completes.\n",
    "    # Optional: Check state for the tool block trigger flag\n",
    "    print(\"\\n--- Inspecting Final Session State (After Tool Guardrail Test) ---\")\n",
    "    # Use the session service instance associated with this stateful session\n",
    "    final_session = await session_service_stateful.get_session(app_name=APP_NAME,\n",
    "                                                         user_id=USER_ID_STATEFUL,\n",
    "                                                         session_id= SESSION_ID_STATEFUL)\n",
    "    if final_session:\n",
    "        # Use .get() for safer access\n",
    "        print(f\"Tool Guardrail Triggered Flag: {final_session.state.get('guardrail_tool_block_triggered', 'Not Set (or False)')}\")\n",
    "        print(f\"Last Weather Report: {final_session.state.get('last_weather_report', 'Not Set')}\") # Should be London weather if successful\n",
    "        print(f\"Temperature Unit: {final_session.state.get('user_preference_temperature_unit', 'Not Set')}\") # Should be Fahrenheit\n",
    "        # print(f\"Full State Dict: {final_session.state}\") # For detailed view\n",
    "    else:\n",
    "        print(\"\\n❌ Error: Could not retrieve final session state.\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n⚠️ Skipping tool guardrail test. Runner ('runner_root_tool_guardrail') is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55ba9f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
